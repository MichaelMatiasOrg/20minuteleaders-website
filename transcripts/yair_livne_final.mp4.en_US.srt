1
00:00:00,080 --> 00:00:00,679
I think it's, you know,

2
00:00:00,680 --> 00:00:01,571
it's scary at times

3
00:00:01,572 --> 00:00:04,107
because you really are

4
00:00:04,108 --> 00:00:05,919
potentially influencing

5
00:00:05,920 --> 00:00:07,359
the way hundreds of millions

6
00:00:07,360 --> 00:00:08,650
of people think a month.

7
00:00:35,700 --> 00:00:36,371
Yair Livne,

8
00:00:36,372 --> 00:00:37,714
thank you so much for joining me.

9
00:00:37,720 --> 00:00:38,519
How are you?

10
00:00:39,080 --> 00:00:40,439
Good, how are you?

11
00:00:40,440 --> 00:00:41,319
Wonderful.

12
00:00:41,320 --> 00:00:42,879
Where are you calling from right now?

13
00:00:42,880 --> 00:00:44,879
I'm in Palo Alto.

14
00:00:44,880 --> 00:00:46,079
You're in Palo Alto.

15
00:00:46,080 --> 00:00:48,274
And I have to congratulate you

16
00:00:48,275 --> 00:00:49,941
on a pretty big transition

17
00:00:49,942 --> 00:00:51,239
right after many years of Quora.

18
00:00:51,240 --> 00:00:53,199
Also quite a few years,

19
00:00:53,200 --> 00:00:55,319
at least 4 years VP of Product.

20
00:00:55,320 --> 00:00:57,371
You've recently finished

21
00:00:57,372 --> 00:00:59,298
your service there.

22
00:00:59,498 --> 00:01:01,319
And you're on to some different things.

23
00:01:01,320 --> 00:01:02,129
And I'd love to chat

24
00:01:02,130 --> 00:01:03,552
about your experience with Quora

25
00:01:03,553 --> 00:01:04,319
and some of the really

26
00:01:04,320 --> 00:01:05,999
interesting things that you've done,

27
00:01:06,000 --> 00:01:07,559
both that are mainstream today,

28
00:01:07,560 --> 00:01:08,636
but also that weren't

29
00:01:08,836 --> 00:01:10,319
necessarily mainstream back

30
00:01:10,320 --> 00:01:11,959
when you were working on them.

31
00:01:11,960 --> 00:01:13,043
But I'd like to start

32
00:01:13,044 --> 00:01:13,919
all the way back,

33
00:01:13,920 --> 00:01:15,359
going back to Stanford.

34
00:01:15,360 --> 00:01:16,660
You're doing your PhD

35
00:01:16,661 --> 00:01:17,714
over there in economics

36
00:01:17,715 --> 00:01:18,399
and you're working

37
00:01:18,400 --> 00:01:19,895
on some really interesting things

38
00:01:19,896 --> 00:01:20,933
that I just love,

39
00:01:20,934 --> 00:01:21,919
both matching theory

40
00:01:21,920 --> 00:01:23,479
and political economy.

41
00:01:23,480 --> 00:01:24,959
Tell me a little bit about yourself

42
00:01:24,960 --> 00:01:26,279
and what led you to do

43
00:01:26,280 --> 00:01:28,959
that research at Stanford.

44
00:01:28,960 --> 00:01:29,487
Yeah.

45
00:01:29,687 --> 00:01:31,279
A great question.

46
00:01:31,280 --> 00:01:34,399
So, I'm curious about economics

47
00:01:34,400 --> 00:01:36,719
for years before coming to Stanford.

48
00:01:36,720 --> 00:01:39,948
I was doing my BA and master's

49
00:01:40,148 --> 00:01:42,960
at the Hebrew U and Jerusalem.

50
00:01:43,160 --> 00:01:44,143
And was mixing

51
00:01:44,144 --> 00:01:46,279
math and econ throughout.

52
00:01:46,280 --> 00:01:48,639
And I was really interested in this

53
00:01:48,640 --> 00:01:50,919
kind of intersection where

54
00:01:50,920 --> 00:01:53,119
the theory and kind of the beauty

55
00:01:53,120 --> 00:01:54,399
of mathematics can be applied

56
00:01:54,400 --> 00:01:55,479
to real world problems.

57
00:01:55,480 --> 00:01:57,018
Maybe like the epitome of that

58
00:01:57,019 --> 00:01:58,078
is Auction Theory,

59
00:01:58,079 --> 00:01:59,357
which won the Nobel Prize

60
00:01:59,371 --> 00:02:01,086
a few weeks ago.

61
00:02:01,087 --> 00:02:03,276
It was kind of motivating,

62
00:02:03,277 --> 00:02:05,119
kind of energy coming in.

63
00:02:05,120 --> 00:02:06,259
I actually had the chance

64
00:02:06,459 --> 00:02:07,800
to be in quite a few lectures

65
00:02:07,801 --> 00:02:09,959
by Milgrom this past year.

66
00:02:09,960 --> 00:02:10,747
And I have to say

67
00:02:10,947 --> 00:02:12,850
that I didn't understand much,

68
00:02:13,050 --> 00:02:14,119
but it was still

69
00:02:14,120 --> 00:02:15,959
fascinating nevertheless.

70
00:02:15,960 --> 00:02:17,157
Yeah, I was in a reading room

71
00:02:17,158 --> 00:02:19,839
with him for kind of a couple of years.

72
00:02:19,840 --> 00:02:20,903
And it was really fascinating

73
00:02:20,904 --> 00:02:22,971
to kind of see him like think

74
00:02:22,972 --> 00:02:24,299
and kind of

75
00:02:24,300 --> 00:02:25,542
appreciate his point of view

76
00:02:25,543 --> 00:02:26,119
on the world.

77
00:02:26,120 --> 00:02:29,079
It's quite extraordinary.

78
00:02:29,080 --> 00:02:31,599
So, you've doing your research.Yeah.

79
00:02:31,600 --> 00:02:33,120
Yeah.

80
00:02:33,400 --> 00:02:35,799
Anyway, so, I got curious.

81
00:02:35,800 --> 00:02:37,016
What else what other kind

82
00:02:37,017 --> 00:02:38,729
of beautiful mathematical applications

83
00:02:38,730 --> 00:02:39,279
can be used

84
00:02:39,280 --> 00:02:40,898
to understand the world

85
00:02:40,899 --> 00:02:42,879
or maybe improve the world.

86
00:02:42,880 --> 00:02:44,719
And kind of matching markets was

87
00:02:44,720 --> 00:02:45,959
a really fascinating thing.

88
00:02:45,960 --> 00:02:46,959
It was kind of blowing up.

89
00:02:46,960 --> 00:02:48,399
And within economics at the time,

90
00:02:48,400 --> 00:02:50,679
people were innovating on matching theory

91
00:02:50,680 --> 00:02:52,399
to do things like kidney donations

92
00:02:52,400 --> 00:02:53,879
and matching kids to schools

93
00:02:53,880 --> 00:02:55,239
in a really efficient way.

94
00:02:55,240 --> 00:02:57,519
And some of those kind of techniques

95
00:02:57,520 --> 00:02:58,959
were actually implemented then

96
00:02:58,960 --> 00:03:01,479
in the kidney donation market

97
00:03:01,480 --> 00:03:03,159
or in actual school systems like

98
00:03:03,160 --> 00:03:04,159
in Boston, in New York,

99
00:03:04,160 --> 00:03:05,034
which were changing

100
00:03:05,234 --> 00:03:06,786
how they were running things,

101
00:03:06,787 --> 00:03:08,414
using economic theory

102
00:03:08,415 --> 00:03:10,125
and with economists

103
00:03:10,126 --> 00:03:11,439
as kind of the people

104
00:03:11,440 --> 00:03:12,759
planning these systems.

105
00:03:12,760 --> 00:03:13,545
So, that was kind

106
00:03:13,546 --> 00:03:14,371
of how I got pulled

107
00:03:14,372 --> 00:03:17,320
into this area.

108
00:03:18,280 --> 00:03:19,094
So, I have to spend

109
00:03:19,095 --> 00:03:20,079
some time talking about

110
00:03:20,080 --> 00:03:21,772
the beauty of mathematics

111
00:03:21,773 --> 00:03:23,693
and, you know, and enlighten

112
00:03:23,694 --> 00:03:26,066
both myself and a lot of my viewers

113
00:03:26,067 --> 00:03:27,752
that aren't necessarily leaning

114
00:03:27,753 --> 00:03:29,455
into the mathematical world.

115
00:03:29,456 --> 00:03:30,842
I am, but I know a lot of my friends

116
00:03:31,042 --> 00:03:32,879
who are excited about innovation

117
00:03:32,880 --> 00:03:35,039
aren't leaning there.

118
00:03:35,040 --> 00:03:37,319
How does mathematics play a role

119
00:03:37,320 --> 00:03:38,053
into our lives,

120
00:03:38,054 --> 00:03:39,929
whether it's matching theory

121
00:03:39,930 --> 00:03:41,514
or political economy?

122
00:03:41,520 --> 00:03:43,339
I'd love to really understand

123
00:03:43,340 --> 00:03:44,479
this world a little bit better

124
00:03:44,480 --> 00:03:46,079
and show some of the excitement.

125
00:03:46,080 --> 00:03:46,319
Yeah.

126
00:03:46,320 --> 00:03:48,719
So, for me, a lot of it comes from

127
00:03:48,720 --> 00:03:50,123
and I think that's kind of

128
00:03:50,124 --> 00:03:50,879
the modern way

129
00:03:50,880 --> 00:03:51,900
to view economics

130
00:03:51,901 --> 00:03:53,039
is from incentives.

131
00:03:53,040 --> 00:03:54,839
So, if you can

132
00:03:54,840 --> 00:03:56,679
describe with a little bit of math,

133
00:03:56,680 --> 00:03:57,868
it doesn't need to be

134
00:03:58,068 --> 00:03:59,000
super sophisticated

135
00:03:59,001 --> 00:04:01,009
what people's preferences are

136
00:04:01,010 --> 00:04:03,959
and what kind of outcomes they prefer.

137
00:04:03,960 --> 00:04:06,186
Then you can model the world

138
00:04:06,187 --> 00:04:08,957
again, with fairly simple primitives

139
00:04:08,958 --> 00:04:11,399
and use this description

140
00:04:11,400 --> 00:04:12,879
of incentives to predict behavior.

141
00:04:12,880 --> 00:04:14,159
And if you can predict behavior,

142
00:04:14,160 --> 00:04:16,872
then you can go one step higher

143
00:04:16,873 --> 00:04:19,759
and describe what kind of systems

144
00:04:19,760 --> 00:04:21,354
would actually push forward

145
00:04:21,355 --> 00:04:22,239
better behavior

146
00:04:22,240 --> 00:04:24,719
on the part of economic agents.

147
00:04:24,720 --> 00:04:26,266
So, in the case of,

148
00:04:26,267 --> 00:04:28,529
let's say, school choice,

149
00:04:28,530 --> 00:04:31,481
if people have preferences over schools

150
00:04:31,482 --> 00:04:33,222
and they want to be matched

151
00:04:33,223 --> 00:04:35,171
with a specific school for their kid,

152
00:04:35,172 --> 00:04:36,157
and that might involve

153
00:04:36,158 --> 00:04:37,371
many different types

154
00:04:37,372 --> 00:04:38,319
of considerations, like

155
00:04:38,320 --> 00:04:39,214
what are your, you know,

156
00:04:39,215 --> 00:04:40,719
the other kids in the family,

157
00:04:40,720 --> 00:04:41,519
are they going already

158
00:04:41,520 --> 00:04:43,959
to school within the system.

159
00:04:43,960 --> 00:04:45,399
What kind of focus areas

160
00:04:45,400 --> 00:04:46,239
that that school have

161
00:04:46,240 --> 00:04:47,839
and is that a good match

162
00:04:47,840 --> 00:04:48,839
for their child or not.

163
00:04:48,840 --> 00:04:50,117
How close is the school

164
00:04:50,118 --> 00:04:51,342
to where they live.

165
00:04:51,343 --> 00:04:53,279
And kind of model all of that out.

166
00:04:53,280 --> 00:04:55,159
And again, this is not rocket science.

167
00:04:55,160 --> 00:04:57,719
This is just a fairly simple

168
00:04:57,720 --> 00:04:59,422
ways of creating kind of

169
00:04:59,622 --> 00:05:00,840
list of preferences.

170
00:05:00,960 --> 00:05:01,872
Then you can think of,

171
00:05:02,072 --> 00:05:03,227
okay, if I ask people

172
00:05:03,228 --> 00:05:04,461
and have incentives

173
00:05:04,462 --> 00:05:06,461
that are aligned in the sense that

174
00:05:06,661 --> 00:05:07,049
the system

175
00:05:07,050 --> 00:05:09,376
will actually respect your preferences

176
00:05:09,377 --> 00:05:10,999
and give you the best outcome

177
00:05:11,000 --> 00:05:13,759
for the preferences you stated,

178
00:05:13,760 --> 00:05:14,339
then you can think

179
00:05:14,340 --> 00:05:15,357
of designing these systems

180
00:05:15,358 --> 00:05:17,958
in a way where matching is "optimal"

181
00:05:17,959 --> 00:05:19,584
and you can get the best outcomes

182
00:05:19,585 --> 00:05:20,319
for the most like

183
00:05:20,320 --> 00:05:21,719
the largest amount of people.

184
00:05:21,720 --> 00:05:23,600
So, that's for me,

185
00:05:23,601 --> 00:05:24,904
really neat thing

186
00:05:24,905 --> 00:05:25,953
where you can take

187
00:05:25,954 --> 00:05:27,386
mathematical models

188
00:05:27,586 --> 00:05:29,399
and kind of solve them in a way

189
00:05:29,400 --> 00:05:32,079
which generate better outcomes for people

190
00:05:32,080 --> 00:05:34,039
in their real lives, on the things

191
00:05:34,040 --> 00:05:35,840
that matter most to them.

192
00:05:37,200 --> 00:05:37,814
100%.

193
00:05:37,815 --> 00:05:38,514
And I have to say

194
00:05:38,515 --> 00:05:40,157
that I've been getting exposed

195
00:05:40,158 --> 00:05:42,399
to the process of residency

196
00:05:42,400 --> 00:05:44,804
and doctors, people in medical school

197
00:05:45,004 --> 00:05:46,320
that are getting there.

198
00:05:46,520 --> 00:05:48,239
You know, on one hand it seems,

199
00:05:48,240 --> 00:05:49,759
yes, matching is a problem.

200
00:05:49,760 --> 00:05:50,759
It's a little bit longer.

201
00:05:50,760 --> 00:05:52,079
Sometimes it's not ideal.

202
00:05:52,080 --> 00:05:53,072
But then, when you meet

203
00:05:53,073 --> 00:05:54,214
the person that's actually

204
00:05:54,215 --> 00:05:54,971
going through that process

205
00:05:54,972 --> 00:05:55,786
and this is not

206
00:05:55,787 --> 00:05:57,239
a life threatening situation.

207
00:05:57,240 --> 00:05:57,679
Right?

208
00:05:57,680 --> 00:05:58,897
Like kidney donations

209
00:05:59,097 --> 00:05:59,999
or stuff like that.

210
00:06:00,000 --> 00:06:00,986
But you can still see

211
00:06:00,987 --> 00:06:02,798
the impact of what

212
00:06:02,799 --> 00:06:04,155
mathematics and algorithms

213
00:06:04,156 --> 00:06:06,355
can do to help ease the process,

214
00:06:06,700 --> 00:06:08,199
let alone save lives.

215
00:06:08,200 --> 00:06:10,269
That is beautiful as you mentioned.

216
00:06:10,270 --> 00:06:11,240
That is beautiful mathematics.

217
00:06:11,440 --> 00:06:12,542
And I'm extremely excited

218
00:06:12,742 --> 00:06:13,857
to continue my studies

219
00:06:14,057 --> 00:06:15,479
and get to those levels.

220
00:06:15,480 --> 00:06:16,481
And then what about

221
00:06:16,681 --> 00:06:17,639
the political economy?

222
00:06:17,640 --> 00:06:21,042
How does math play into politics

223
00:06:21,043 --> 00:06:21,956
and what's coming there?

224
00:06:21,957 --> 00:06:22,942
Yeah. So, fun fact there is I got pulled

225
00:06:23,104 --> 00:06:23,828
into it through my wife,

226
00:06:23,829 --> 00:06:24,885
who is also doing a PhD

227
00:06:24,886 --> 00:06:26,079
at Stanford at the same time.

228
00:06:26,080 --> 00:06:26,736
And she was in

229
00:06:26,737 --> 00:06:28,157
the political science department,

230
00:06:28,158 --> 00:06:30,225
but actually had a very similar background

231
00:06:30,226 --> 00:06:31,914
from a kind of game theory

232
00:06:31,915 --> 00:06:34,357
and mathematics perspective.

233
00:06:35,000 --> 00:06:36,879
And we were both kind of curious.

234
00:06:36,880 --> 00:06:38,879
This is like again,

235
00:06:38,880 --> 00:06:39,740
really good timing

236
00:06:39,741 --> 00:06:40,997
because we were doing this

237
00:06:40,998 --> 00:06:41,998
kind of pre Arab Spring.

238
00:06:41,999 --> 00:06:43,262
But we got really curious

239
00:06:43,263 --> 00:06:44,633
on this topic of protests,

240
00:06:44,634 --> 00:06:45,670
especially protests

241
00:06:45,671 --> 00:06:47,279
in authoritarian regimes.

242
00:06:47,280 --> 00:06:48,117
So, these are people

243
00:06:48,118 --> 00:06:49,303
who are taking a big chance

244
00:06:49,304 --> 00:06:50,529
and risking their lives

245
00:06:50,530 --> 00:06:53,317
and going to voice their concerns

246
00:06:53,318 --> 00:06:54,956
or their objections

247
00:06:54,957 --> 00:06:56,971
to the regime under the threat

248
00:06:56,972 --> 00:07:00,000
of arrest or execution.

249
00:07:00,520 --> 00:07:01,919
And why are they doing that?

250
00:07:01,920 --> 00:07:03,639
What kind of dynamics contribute

251
00:07:03,640 --> 00:07:04,943
to them taking that chance?

252
00:07:04,944 --> 00:07:05,786
What are they looking

253
00:07:05,787 --> 00:07:07,319
to get out of it?

254
00:07:07,320 --> 00:07:08,645
And so, we were using

255
00:07:08,646 --> 00:07:09,924
a kind of a mix approach

256
00:07:09,925 --> 00:07:11,328
of both looking at empirical data,

257
00:07:11,329 --> 00:07:12,099
but also building

258
00:07:12,100 --> 00:07:13,411
a mathematical model

259
00:07:13,412 --> 00:07:14,636
that would try to explain

260
00:07:14,637 --> 00:07:15,643
under what conditions,

261
00:07:15,644 --> 00:07:17,173
would people actually take that chance

262
00:07:17,373 --> 00:07:20,199
and again, take on meaningful cost

263
00:07:20,200 --> 00:07:21,599
to get an outcome.

264
00:07:21,600 --> 00:07:23,279
And that outcome is political.

265
00:07:23,280 --> 00:07:25,799
And so it kind of reached

266
00:07:25,800 --> 00:07:27,036
a model where, you know,

267
00:07:27,037 --> 00:07:29,450
the economic conditions were often

268
00:07:29,856 --> 00:07:31,079
a strong determinant

269
00:07:31,080 --> 00:07:33,519
of when protests might happen.

270
00:07:33,520 --> 00:07:34,867
And what's the probability

271
00:07:34,961 --> 00:07:37,759
of that protest actually having an impact.

272
00:07:37,760 --> 00:07:38,600
And again, the timing

273
00:07:38,601 --> 00:07:39,759
was really opportune

274
00:07:39,760 --> 00:07:41,157
because we were doing this just before

275
00:07:41,158 --> 00:07:42,687
the kind of Arab Spring

276
00:07:42,688 --> 00:07:44,571
where we saw this actually play out

277
00:07:44,572 --> 00:07:45,957
with many, many regimes

278
00:07:45,958 --> 00:07:48,400
being toppled or at least shaken

279
00:07:48,401 --> 00:07:50,343
by mass protest movements,

280
00:07:50,344 --> 00:07:52,439
something that wasn't seen

281
00:07:52,440 --> 00:07:53,639
for basically decades.

282
00:07:53,640 --> 00:07:54,285
So, when we were

283
00:07:54,286 --> 00:07:55,842
originally taking on this research,

284
00:07:55,843 --> 00:07:56,842
it was kind of out of vague

285
00:07:56,843 --> 00:07:58,550
to study protest

286
00:07:58,551 --> 00:07:59,679
because it was like

287
00:07:59,680 --> 00:08:00,507
this never happens

288
00:08:00,589 --> 00:08:01,999
or this isn't meaningful.

289
00:08:02,000 --> 00:08:03,834
And then, a year or two later

290
00:08:03,835 --> 00:08:05,079
we saw all of this unfold.

291
00:08:05,080 --> 00:08:06,058
So, it was really

292
00:08:06,059 --> 00:08:07,439
kind of a fun experience

293
00:08:07,440 --> 00:08:09,559
to be thinking about these problems.

294
00:08:09,560 --> 00:08:11,519
So, Yair, you're working on these

295
00:08:11,520 --> 00:08:12,948
mathematical models.

296
00:08:12,949 --> 00:08:15,871
You're thinking about all this

297
00:08:15,872 --> 00:08:18,071
and all of a sudden, the Arab Spring happens,

298
00:08:18,286 --> 00:08:19,759
and you're watching this.

299
00:08:19,760 --> 00:08:22,329
And I have to get into

300
00:08:22,529 --> 00:08:24,159
the perspective that you're at,

301
00:08:24,160 --> 00:08:26,959
I believe, it's like 2010, 2011.

302
00:08:26,960 --> 00:08:28,360
Right?

303
00:08:28,680 --> 00:08:30,079
How does this all play out?

304
00:08:30,080 --> 00:08:31,159
Are you surprised?

305
00:08:31,614 --> 00:08:36,039
Does this research take on a greater role?

306
00:08:36,040 --> 00:08:38,040
What happens there?

307
00:08:38,560 --> 00:08:38,865
Yeah.

308
00:08:39,065 --> 00:08:40,759
So I, we definitely were surprised.

309
00:08:40,760 --> 00:08:42,383
Again, this was not something

310
00:08:42,384 --> 00:08:44,726
that we had seen since probably

311
00:08:44,727 --> 00:08:46,239
the fall of the Soviet Union,

312
00:08:46,240 --> 00:08:49,159
where people work on toppling regimes

313
00:08:49,160 --> 00:08:51,359
by going out into the streets.

314
00:08:51,360 --> 00:08:52,959
So, it was a shock.

315
00:08:52,960 --> 00:08:55,873
I mean, it is kind of very relevant

316
00:08:55,874 --> 00:08:56,894
or eerily similar to

317
00:08:56,895 --> 00:08:58,557
what the dynamics we described

318
00:08:58,558 --> 00:08:59,799
in our papers,

319
00:08:59,800 --> 00:09:02,959
because ultimately the logic

320
00:09:02,960 --> 00:09:03,919
was kind of very simple.

321
00:09:03,920 --> 00:09:05,079
Things get kind of bad enough

322
00:09:05,080 --> 00:09:06,539
from an economic perspective

323
00:09:06,540 --> 00:09:07,839
where people are desperate enough,

324
00:09:07,840 --> 00:09:09,173
they'll take that chance.

325
00:09:09,174 --> 00:09:11,279
That was the heart of the model.

326
00:09:11,280 --> 00:09:13,970
But really connecting it to the empirics

327
00:09:13,971 --> 00:09:15,157
and actually kind of being able

328
00:09:15,158 --> 00:09:17,279
to predict, this was

329
00:09:17,280 --> 00:09:19,359
the neat part of the research.

330
00:09:19,360 --> 00:09:21,399
And so, it was both surprising,

331
00:09:21,400 --> 00:09:22,679
but very kind of consistent,

332
00:09:22,680 --> 00:09:25,439
at the same time.

333
00:09:25,440 --> 00:09:27,999
And I kind of, both my wife and I were in

334
00:09:28,000 --> 00:09:29,519
the process of kind of leaving academia.

335
00:09:29,520 --> 00:09:30,783
But for the professor

336
00:09:30,784 --> 00:09:31,865
we were working with

337
00:09:31,866 --> 00:09:33,799
in the political science department,

338
00:09:33,800 --> 00:09:34,971
this was a very good boost

339
00:09:34,972 --> 00:09:36,759
for her career.

340
00:09:36,760 --> 00:09:37,559
Unbelievable.

341
00:09:37,560 --> 00:09:40,479
So, you're at that point,

342
00:09:40,480 --> 00:09:42,240
you're leaving academia

343
00:09:42,440 --> 00:09:43,765
and you have a series

344
00:09:43,766 --> 00:09:45,543
of different experiences throughout

345
00:09:45,544 --> 00:09:47,357
your professional career

346
00:09:47,358 --> 00:09:50,999
leading up to your job at Quora now.

347
00:09:51,000 --> 00:09:51,778
I know Quora

348
00:09:51,779 --> 00:09:53,399
as this beautiful website

349
00:09:53,400 --> 00:09:54,719
that I go to, to answer

350
00:09:54,720 --> 00:09:56,039
all of the relevant

351
00:09:56,040 --> 00:09:57,200
and irrelevant questions

352
00:09:57,201 --> 00:09:59,159
that I may have.

353
00:09:59,160 --> 00:10:00,173
But walk me through

354
00:10:00,174 --> 00:10:02,285
a little bit of your life path

355
00:10:02,286 --> 00:10:03,714
that led to being VP of Product

356
00:10:03,715 --> 00:10:04,757
at such an awesome company.

357
00:10:05,160 --> 00:10:05,479
Yeah.

358
00:10:05,480 --> 00:10:07,919
So, it may seem random,

359
00:10:07,920 --> 00:10:08,678
but I think there is

360
00:10:08,679 --> 00:10:10,119
a thread connecting everything,

361
00:10:10,319 --> 00:10:12,560
or at least I'd like to believe so.

362
00:10:12,720 --> 00:10:13,457
So for me,

363
00:10:13,458 --> 00:10:15,381
kind of what I've enjoyed

364
00:10:15,509 --> 00:10:16,743
or what I've been attracted to is

365
00:10:16,744 --> 00:10:18,353
how do we kind of

366
00:10:18,354 --> 00:10:20,353
again, use kind of math

367
00:10:20,354 --> 00:10:22,367
or logic to unlock a lot of value.

368
00:10:22,720 --> 00:10:23,468
And that's something

369
00:10:23,469 --> 00:10:25,001
that's kind of always driven me

370
00:10:25,002 --> 00:10:26,719
or I was passionate about.

371
00:10:26,720 --> 00:10:28,839
And with Quora as an economist,

372
00:10:28,840 --> 00:10:30,800
this is actually a fascinating thing

373
00:10:30,801 --> 00:10:33,039
to dive into because

374
00:10:33,040 --> 00:10:35,079
you can think about Quora,

375
00:10:35,080 --> 00:10:36,759
and I think this is true of knowledge

376
00:10:36,760 --> 00:10:38,639
more generally as a market.

377
00:10:38,640 --> 00:10:40,314
There are people who need

378
00:10:40,315 --> 00:10:41,719
certain answers to certain questions.

379
00:10:41,720 --> 00:10:43,599
Those may be very important or trivial.

380
00:10:43,600 --> 00:10:45,440
That's all fine.

381
00:10:45,560 --> 00:10:47,216
And the other people in the world

382
00:10:47,217 --> 00:10:49,085
who know about the answers to those

383
00:10:49,086 --> 00:10:50,571
and kind of how do you connect

384
00:10:50,572 --> 00:10:52,716
the two sides of this market

385
00:10:53,320 --> 00:10:54,584
and how do you unlock value

386
00:10:54,585 --> 00:10:55,343
and how do you create

387
00:10:55,344 --> 00:10:57,719
the right incentives for people

388
00:10:57,720 --> 00:10:58,557
to be kind of sharing

389
00:10:58,558 --> 00:11:00,839
that online in a public way.

390
00:11:00,840 --> 00:11:02,414
That was like the key question

391
00:11:02,415 --> 00:11:03,359
that motivated me.

392
00:11:03,360 --> 00:11:05,319
And actually my first project

393
00:11:05,320 --> 00:11:06,347
I got put on was

394
00:11:06,348 --> 00:11:07,529
we had what to consider

395
00:11:07,530 --> 00:11:09,079
the time that we later

396
00:11:09,080 --> 00:11:10,719
deprecated called Quora Credits,

397
00:11:10,720 --> 00:11:12,719
which was a way for people

398
00:11:12,720 --> 00:11:15,039
to accumulate kind of virtual money.

399
00:11:15,040 --> 00:11:16,767
This is kind of pre Bitcoin.

400
00:11:17,200 --> 00:11:20,279
Everything about virtual money.

401
00:11:20,280 --> 00:11:21,414
So, accumulate this

402
00:11:21,415 --> 00:11:23,399
kind of point system

403
00:11:23,400 --> 00:11:24,800
and be able to spend it

404
00:11:24,801 --> 00:11:26,755
by asking people directly

405
00:11:26,756 --> 00:11:29,799
for their answers on a question.

406
00:11:29,800 --> 00:11:32,186
So, you basically got an ability

407
00:11:32,187 --> 00:11:34,766
to kind of buy someone's attention

408
00:11:34,767 --> 00:11:36,522
by sending them a notification

409
00:11:36,523 --> 00:11:37,559
and an email saying,

410
00:11:37,560 --> 00:11:39,200
hey, can you answer this question.

411
00:11:39,201 --> 00:11:40,809
And so each person

412
00:11:40,810 --> 00:11:42,794
had kind of a dynamic price

413
00:11:42,795 --> 00:11:44,529
of how much is their attention worth.

414
00:11:44,530 --> 00:11:45,357
And that was based

415
00:11:45,358 --> 00:11:46,679
on supply and demand

416
00:11:46,680 --> 00:11:48,959
dynamics in the marketplace.

417
00:11:48,960 --> 00:11:50,442
And again, if you are

418
00:11:50,443 --> 00:11:52,128
a good member of the community

419
00:11:52,129 --> 00:11:53,780
and you supply value yourself,

420
00:11:53,781 --> 00:11:54,743
then you were able

421
00:11:54,744 --> 00:11:56,131
to kind of utilize that

422
00:11:56,132 --> 00:11:57,160
and kind of get value

423
00:11:57,161 --> 00:11:58,049
or get knowledge

424
00:11:58,050 --> 00:11:59,279
out of somebody else's head.

425
00:11:59,280 --> 00:12:00,042
That was kind of

426
00:12:00,043 --> 00:12:01,279
a beautiful concept to me.

427
00:12:01,280 --> 00:12:02,199
And something that really pulled me

428
00:12:02,200 --> 00:12:05,640
into working for the company.

429
00:12:05,720 --> 00:12:06,124
Wow.

430
00:12:06,324 --> 00:12:07,439
So, you know,

431
00:12:07,440 --> 00:12:09,059
a marketplace of knowledge

432
00:12:09,060 --> 00:12:10,916
in an age of misinformation.

433
00:12:10,917 --> 00:12:12,079
You know,

434
00:12:12,080 --> 00:12:14,719
you're VP of Product, I believe,

435
00:12:14,720 --> 00:12:16,239
all the way back from 2016.

436
00:12:16,240 --> 00:12:16,399
Right?

437
00:12:16,400 --> 00:12:18,119
You're seeing what has happened

438
00:12:18,120 --> 00:12:19,186
with the election

439
00:12:19,187 --> 00:12:22,138
and when I look on social media

440
00:12:22,139 --> 00:12:24,719
and those sorts of areas,

441
00:12:24,720 --> 00:12:25,979
it's very hard for me

442
00:12:25,980 --> 00:12:27,461
not to be pessimistic about,

443
00:12:27,462 --> 00:12:29,114
about where we're headed with,

444
00:12:29,115 --> 00:12:30,079
with misinformation.

445
00:12:30,080 --> 00:12:32,639
And it's almost like a promise to myself

446
00:12:32,640 --> 00:12:35,399
that I'll only really accept knowledge

447
00:12:35,400 --> 00:12:37,338
when I see it cross sectioning

448
00:12:37,339 --> 00:12:38,771
from various sources,

449
00:12:38,772 --> 00:12:40,239
and I take pride in that.

450
00:12:40,240 --> 00:12:40,986
But how do you,

451
00:12:40,987 --> 00:12:42,119
as VP of Product,

452
00:12:42,120 --> 00:12:43,929
approach this mentality

453
00:12:43,930 --> 00:12:45,705
that we have a real issue

454
00:12:45,706 --> 00:12:46,359
on our hands

455
00:12:46,360 --> 00:12:47,639
and it's growing exponentially?

456
00:12:47,640 --> 00:12:47,959
Right?

457
00:12:47,960 --> 00:12:49,039
I mean, it's getting out of control.

458
00:12:49,040 --> 00:12:51,119
Yeah. That's a great question.

459
00:12:51,120 --> 00:12:52,079
And I think for us, like,

460
00:12:52,080 --> 00:12:54,439
while we were actually very

461
00:12:54,440 --> 00:12:55,986
kind of in some sense validated

462
00:12:55,987 --> 00:12:57,277
by all of this happening,

463
00:12:57,278 --> 00:12:58,957
that this is kind of sounds ironic.

464
00:12:58,960 --> 00:13:00,388
But we at that point

465
00:13:00,389 --> 00:13:02,559
had been worried about, you know,

466
00:13:02,560 --> 00:13:03,620
kind of misinformation

467
00:13:03,621 --> 00:13:05,386
or just generally what's true or not

468
00:13:05,387 --> 00:13:05,957
for many years.

469
00:13:05,958 --> 00:13:07,670
For us, you know,

470
00:13:07,671 --> 00:13:08,999
our mission is to share

471
00:13:09,000 --> 00:13:10,119
and grow the world's knowledge.

472
00:13:10,120 --> 00:13:11,529
And by that we mean real knowledge

473
00:13:11,530 --> 00:13:13,599
that is useful to people.

474
00:13:13,600 --> 00:13:15,839
Misinformation is something that undermines,

475
00:13:15,840 --> 00:13:16,519
as you were saying,

476
00:13:16,520 --> 00:13:17,559
people's trust and knowledge.

477
00:13:17,560 --> 00:13:18,206
So, for us,

478
00:13:18,207 --> 00:13:19,919
that was an existential threat

479
00:13:19,920 --> 00:13:23,360
if the platform can be manipulated

480
00:13:23,600 --> 00:13:26,133
into showing prominently

481
00:13:26,134 --> 00:13:27,646
or spreading information,

482
00:13:27,647 --> 00:13:28,959
that's not actually true.

483
00:13:28,960 --> 00:13:29,759
That undermines trust

484
00:13:29,760 --> 00:13:30,959
in the platform.

485
00:13:30,960 --> 00:13:31,919
That reduces the incentive

486
00:13:31,920 --> 00:13:33,799
for people to start search for knowledge.

487
00:13:33,800 --> 00:13:34,971
And because of this marketplace

488
00:13:34,972 --> 00:13:36,314
that I was describing,

489
00:13:36,315 --> 00:13:37,679
it also reduces the incentives

490
00:13:37,680 --> 00:13:39,514
of good people to actually share

491
00:13:39,515 --> 00:13:40,804
the right information

492
00:13:40,805 --> 00:13:41,586
because there's all this

493
00:13:41,587 --> 00:13:43,129
other junk out there

494
00:13:43,130 --> 00:13:44,371
that might drown out

495
00:13:44,372 --> 00:13:45,400
what they are saying

496
00:13:45,401 --> 00:13:46,719
or what they are sharing.

497
00:13:46,720 --> 00:13:47,429
So for us, we were thinking

498
00:13:47,430 --> 00:13:49,839
about this problem years earlier.

499
00:13:49,840 --> 00:13:52,279
One of the key moments for me

500
00:13:52,280 --> 00:13:53,919
in that journey was

501
00:13:53,920 --> 00:13:54,912
we had to digest email

502
00:13:55,112 --> 00:13:57,910
or still have to digest email.

503
00:13:57,911 --> 00:13:59,840
It's a more popular kind of

504
00:13:59,920 --> 00:14:02,051
emails out there that go out

505
00:14:02,052 --> 00:14:04,065
and hundreds of millions of people

506
00:14:04,265 --> 00:14:06,279
and has personalized information for them,

507
00:14:06,280 --> 00:14:07,679
something we had invested a lot in.

508
00:14:07,680 --> 00:14:08,843
And there was

509
00:14:09,557 --> 00:14:12,599
I believe this was in 2014 or 2015,

510
00:14:12,600 --> 00:14:14,159
we had sent out

511
00:14:14,160 --> 00:14:15,307
to, if I remember correctly,

512
00:14:15,308 --> 00:14:16,199
hundreds of thousands

513
00:14:16,200 --> 00:14:17,758
or a few million people

514
00:14:17,759 --> 00:14:18,999
and answer at the top

515
00:14:19,000 --> 00:14:19,923
of their email

516
00:14:19,924 --> 00:14:21,386
that had basically kind of

517
00:14:21,387 --> 00:14:23,638
a 9/11 conspiracy theory content in it

518
00:14:23,639 --> 00:14:25,119
like feature prominently.

519
00:14:25,120 --> 00:14:25,571
And that was like

520
00:14:25,572 --> 00:14:26,514
a real wake up moment

521
00:14:26,520 --> 00:14:28,039
of hey, we're

522
00:14:28,040 --> 00:14:29,919
approaching this purely algorithmically

523
00:14:29,920 --> 00:14:32,999
with all these algorithms that

524
00:14:33,000 --> 00:14:34,239
trying to understand what people like,

525
00:14:34,240 --> 00:14:35,119
but we do this on

526
00:14:35,120 --> 00:14:36,359
the basis of fairly kind

527
00:14:36,360 --> 00:14:37,479
of shallow signals like

528
00:14:37,480 --> 00:14:39,359
clicks and uploads,

529
00:14:39,360 --> 00:14:41,759
we may fall into these traps.

530
00:14:41,760 --> 00:14:42,592
And we really have

531
00:14:42,593 --> 00:14:43,786
to put in some guardrails

532
00:14:43,787 --> 00:14:45,957
and make sure that we don't let

533
00:14:45,958 --> 00:14:49,439
that kind of, "information to take over".

534
00:14:49,440 --> 00:14:50,259
And so, we have been thinking

535
00:14:50,260 --> 00:14:51,143
about this for years

536
00:14:51,144 --> 00:14:52,639
before the election

537
00:14:52,640 --> 00:14:53,557
and for us kind of seeing

538
00:14:53,558 --> 00:14:54,972
the rest of the industry

539
00:14:54,973 --> 00:14:55,999
suddenly realized, hey,

540
00:14:56,000 --> 00:14:57,839
there's a massive kind of problem here

541
00:14:57,840 --> 00:15:00,279
and we should start kind of

542
00:15:00,280 --> 00:15:01,571
being a lot more careful

543
00:15:01,572 --> 00:15:04,479
about "free speech",

544
00:15:04,480 --> 00:15:06,479
was again, validating in some sense

545
00:15:06,480 --> 00:15:07,479
because we had been working

546
00:15:07,480 --> 00:15:09,640
on this for years.

547
00:15:11,080 --> 00:15:13,171
Wow. That's a lot of responsibility,

548
00:15:13,172 --> 00:15:14,142
isn't it?

549
00:15:14,143 --> 00:15:17,107
To sit in that chair and understand that

550
00:15:17,108 --> 00:15:19,359
the things that you're working on

551
00:15:19,360 --> 00:15:21,839
are the core of information?

552
00:15:21,840 --> 00:15:22,479
Absolutely.

553
00:15:22,480 --> 00:15:24,599
I mean, I think it's scary at times

554
00:15:24,600 --> 00:15:27,199
because you really are

555
00:15:27,200 --> 00:15:28,426
potentially influencing

556
00:15:28,427 --> 00:15:30,171
the way hundreds of millions

557
00:15:30,172 --> 00:15:31,601
of people think a month

558
00:15:31,800 --> 00:15:33,929
and that those, you know,

559
00:15:34,360 --> 00:15:35,903
subtle nudges towards

560
00:15:36,103 --> 00:15:37,978
believing things aren't true

561
00:15:38,178 --> 00:15:40,719
are risky from a political perspective,

562
00:15:40,720 --> 00:15:43,119
social stability perspective,

563
00:15:43,120 --> 00:15:43,557
medical advice,

564
00:15:43,558 --> 00:15:44,959
like all these areas

565
00:15:44,960 --> 00:15:47,399
are hyper important to people's lives.

566
00:15:47,400 --> 00:15:48,988
And if you're pushing

567
00:15:48,989 --> 00:15:51,559
the wrong stuff out there,

568
00:15:51,560 --> 00:15:53,199
that is the opposite of our mission.

569
00:15:53,200 --> 00:15:54,759
That is dangerous.

570
00:15:54,760 --> 00:15:56,799
And so, that's kind

571
00:15:56,800 --> 00:15:58,959
of a fear or concern.

572
00:15:58,960 --> 00:16:01,439
Again, we were occupied

573
00:16:01,440 --> 00:16:03,519
with for a long time.

574
00:16:03,520 --> 00:16:05,150
And it's just to call that

575
00:16:05,151 --> 00:16:07,371
and be kind of a little charitable

576
00:16:07,372 --> 00:16:08,959
to other platforms

577
00:16:08,960 --> 00:16:10,879
is a really kind of tricky area.

578
00:16:10,880 --> 00:16:11,314
You don't want to,

579
00:16:11,315 --> 00:16:13,079
it's very hard to

580
00:16:13,080 --> 00:16:14,510
be the voice of truth

581
00:16:14,511 --> 00:16:17,196
and be an arbiter of every little fact.

582
00:16:17,400 --> 00:16:18,879
We're talking about millions

583
00:16:18,880 --> 00:16:21,399
and millions of answers a week.

584
00:16:21,400 --> 00:16:22,719
What's true or not.

585
00:16:22,720 --> 00:16:24,236
Nobody can kind of sift through that

586
00:16:24,237 --> 00:16:25,079
and make a decision.

587
00:16:25,080 --> 00:16:25,796
You even saw this

588
00:16:25,797 --> 00:16:26,571
with the pandemic

589
00:16:26,629 --> 00:16:27,700
where the early information

590
00:16:27,701 --> 00:16:29,449
that the most credible agencies

591
00:16:29,450 --> 00:16:31,335
were pushing out was actually false.

592
00:16:31,535 --> 00:16:32,199
And at that time

593
00:16:32,200 --> 00:16:34,359
is very hard to make that call.

594
00:16:34,360 --> 00:16:36,639
So, you need to strike this balance

595
00:16:36,640 --> 00:16:37,814
of allowing debate

596
00:16:37,815 --> 00:16:41,199
and allowing enough spectrum of views

597
00:16:41,200 --> 00:16:43,879
to kind of have its fight out there

598
00:16:43,880 --> 00:16:46,359
and kind of have that evolution of ideas.

599
00:16:46,360 --> 00:16:47,679
But at the same time,

600
00:16:47,680 --> 00:16:48,171
the stuff that's

601
00:16:48,172 --> 00:16:50,031
kind of intentionally false

602
00:16:50,032 --> 00:16:51,412
or deliberately misleading

603
00:16:51,413 --> 00:16:53,559
or is kind of the conspiracy theory realm,

604
00:16:53,560 --> 00:16:55,158
have a really hard line there

605
00:16:55,159 --> 00:16:56,506
and have the mechanisms in place

606
00:16:56,507 --> 00:16:59,835
where you can squash that when it arises.

607
00:17:00,400 --> 00:17:01,430
So, it's really unfair

608
00:17:01,431 --> 00:17:02,571
that I'm asking you this

609
00:17:02,572 --> 00:17:03,921
when we have literally

610
00:17:03,922 --> 00:17:04,953
a minute and a half

611
00:17:04,954 --> 00:17:06,001
to the interview,

612
00:17:06,002 --> 00:17:07,199
but where are we headed?

613
00:17:07,200 --> 00:17:08,571
What needs to happen

614
00:17:08,572 --> 00:17:11,039
so that when I watch

615
00:17:11,040 --> 00:17:12,230
as I watch my niece,

616
00:17:12,231 --> 00:17:13,479
who is six years old,

617
00:17:13,480 --> 00:17:14,586
as she grows up

618
00:17:14,786 --> 00:17:15,839
and she gets more

619
00:17:15,840 --> 00:17:17,146
into social media

620
00:17:17,147 --> 00:17:18,743
and she's so curious,

621
00:17:18,760 --> 00:17:20,559
how can I help her?

622
00:17:20,560 --> 00:17:22,319
How can the world help her

623
00:17:22,320 --> 00:17:24,039
gain curiosity in the right way?

624
00:17:24,040 --> 00:17:24,919
Yeah. I think that's

625
00:17:24,920 --> 00:17:26,079
a really key question.

626
00:17:26,080 --> 00:17:26,971
And I think that, you know,

627
00:17:26,972 --> 00:17:29,186
this is a really interesting

628
00:17:29,187 --> 00:17:31,879
intersection of regulation,

629
00:17:31,880 --> 00:17:33,239
kind of a corporate responsibility

630
00:17:33,240 --> 00:17:34,866
on the side of platforms.

631
00:17:35,066 --> 00:17:35,679
And frankly,

632
00:17:35,680 --> 00:17:36,759
a lot more, I think, debate

633
00:17:36,760 --> 00:17:37,599
that needs to happen there.

634
00:17:37,600 --> 00:17:40,159
So, I don't have like a magic bullet,

635
00:17:40,160 --> 00:17:42,279
but I do think platforms need to spend

636
00:17:42,280 --> 00:17:45,199
a lot more thought and time about

637
00:17:45,200 --> 00:17:46,954
kind of striking that balance

638
00:17:46,955 --> 00:17:48,840
and making sure their algorithms

639
00:17:48,841 --> 00:17:49,754
don't kind of trend

640
00:17:49,755 --> 00:17:51,343
or have these feedback loops

641
00:17:51,344 --> 00:17:53,452
that end up in these places

642
00:17:53,453 --> 00:17:54,719
where people become

643
00:17:54,720 --> 00:17:56,679
convinced of flat earth theories for real.

644
00:17:56,680 --> 00:17:57,980
Because of like some rabbit hole

645
00:17:57,981 --> 00:17:59,919
they went down through YouTube.

646
00:17:59,920 --> 00:18:01,370
So, I honestly think

647
00:18:01,371 --> 00:18:03,032
that the right solution

648
00:18:03,033 --> 00:18:03,986
is some regulation,

649
00:18:03,987 --> 00:18:05,799
potentially not a massive amount,

650
00:18:05,800 --> 00:18:06,400
but a lot more

651
00:18:06,401 --> 00:18:08,399
kind of corporate effort

652
00:18:08,400 --> 00:18:10,314
to kind of squash these pockets

653
00:18:10,315 --> 00:18:13,520
of the Internet that are really dangerous.

654
00:18:13,880 --> 00:18:15,399
Right. And we've obviously seen

655
00:18:15,400 --> 00:18:18,239
the sensitivity behind this,

656
00:18:18,240 --> 00:18:19,959
the intersection between regulation

657
00:18:19,960 --> 00:18:21,016
and private companies

658
00:18:21,017 --> 00:18:21,973
and what's happening,

659
00:18:21,974 --> 00:18:22,839
especially as we've seen

660
00:18:22,840 --> 00:18:24,319
in the most recent election,

661
00:18:24,320 --> 00:18:25,679
as some of Twitter's action,

662
00:18:25,680 --> 00:18:27,639
some of Facebook's actions that

663
00:18:27,640 --> 00:18:29,571
even a single action could

664
00:18:29,572 --> 00:18:32,214
like flagging a comment by

665
00:18:32,480 --> 00:18:33,879
an official in the White House says

666
00:18:33,880 --> 00:18:36,279
something that maybe not correct,

667
00:18:36,280 --> 00:18:37,052
that stirs up

668
00:18:37,053 --> 00:18:38,379
some very meaningful

669
00:18:38,380 --> 00:18:40,519
conversations about the foundation

670
00:18:40,520 --> 00:18:42,357
of what is the responsibility

671
00:18:42,358 --> 00:18:44,159
of these private companies.

672
00:18:44,160 --> 00:18:45,759
As well as what is the responsibility

673
00:18:45,760 --> 00:18:47,039
for their own company,

674
00:18:47,040 --> 00:18:48,319
but also for the citizens

675
00:18:48,320 --> 00:18:49,557
and for the integrity

676
00:18:49,558 --> 00:18:51,600
of a free and fair election

677
00:18:51,601 --> 00:18:53,043
or democracy.

678
00:18:53,357 --> 00:18:54,639
Yair, I want to thank you

679
00:18:54,640 --> 00:18:55,786
for being so kind with your time

680
00:18:55,787 --> 00:18:56,719
and so generous.

681
00:18:56,720 --> 00:18:57,636
I can go on this

682
00:18:57,836 --> 00:18:58,839
for another two hours

683
00:18:58,840 --> 00:18:59,579
because everything

684
00:18:59,580 --> 00:19:01,014
that we've touched here

685
00:19:01,015 --> 00:19:02,529
is so fascinating

686
00:19:02,530 --> 00:19:04,439
and so remarkable.

687
00:19:04,440 --> 00:19:06,599
So, thank you for sharing that with me.

688
00:19:06,600 --> 00:19:07,399
Before we leave,

689
00:19:07,400 --> 00:19:08,196
I have to ask you

690
00:19:08,197 --> 00:19:08,796
for three words

691
00:19:08,797 --> 00:19:09,496
that you would use

692
00:19:09,497 --> 00:19:10,302
to describe yourself.

693
00:19:10,303 --> 00:19:11,159
Optimistic,

694
00:19:11,160 --> 00:19:14,600
persistent and curious.

695
00:19:15,080 --> 00:19:16,497
So, after all of that,

696
00:19:16,697 --> 00:19:18,408
optimistic, persistent and curious.

697
00:19:18,608 --> 00:19:19,222
I just love it.

698
00:19:19,422 --> 00:19:19,959
Thank you so much, Yair.

699
00:19:19,960 --> 00:19:21,519
This was just wonderful. Toda raba.

700
00:19:21,520 --> 00:19:22,200
Thank you so much.

