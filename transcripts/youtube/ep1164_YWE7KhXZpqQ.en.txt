something is completely different right
now with scale variation
uh the automation of it the
personalization of it things that we
haven't seen before uh that it's the
relation is still unclear what we do see
is what we starting and uh other uh
researchers defined it as like reality
apathy so we're starting to see this
overwhelming uh for the public the
overwhelmed public that's starting to
just disengage with the idea of like
trying to identify what is real or fake
and everything become fake uh in some
ways and we do see how people in power
are using that uh uh notion of uh and
the the easiness of undermining trust.
You see how uh many people in power when
they saying stuff that they wish they
didn't say or they wish those uh
conversation were not leaked to the uh
press they uh immediately calling it
fake right and uh it started as a fake
news type of title now it's AI so we see
this it's not a new risk and it's not a
new burden that sits on journalists and
fact checkers but the scale of it is so
overwhelming and the techn the technical
barrier are starting to be very hard to
um to work around especially in the in
the global war.
[Music]
Shireen Anlin, welcome to the human zero
day. Thank you so much for joining me uh
for another part of the speaker series.
I'm I'm really excited to have you here.
Thank you.
&gt;&gt; Thank you, Michael. I'm excited to be
here. Shirene, we we've known each other
now for I I think a little bit more, a
little bit over a year. um you have an
incredible
I think opportunity with what you're
doing with witness in the context of
human rights in the context of
misinformation of disinformation
areas where it really matters areas of
of extremely high impact and getting a
front row seat to seeing how AI
generated content is impacting different
um ecosystems different populations
um a lot of us I think are you know
we've talked about how in other episodes
about how we have these echo chambers on
social media and but you get to live
outside of your echo chamber because you
get exposed to the different things that
the media has to offer. And so really
excited to hear a little bit more about
this intersection point. But before we
get into that, can you share with me a
little bit about your own background,
your own story? How did you get involved
with this type of work?
&gt;&gt; Uh of course. Uh so I'm Shane. H I'm
originally from Israel but I'm based in
Brooklyn. Uh my background started as um
interactive storytelling. I I did a
project with VR AR using machine
learning as well to develop stories
based on real life stories. Uh um de
develop experiences immersive
experiences like immersive theater or
interactive uh way of experiencing
things in VR. Um and slowly I started to
feel I need more I need to understand
more or engage better around the impact
of the technology I've been using but
also uh uh thinking about the stories
I've been trying to tell what is
actually who what who is the audience
that is reach. So that's what led me to
witness. Uh I started to look around and
I saw uh the position for media
technologist and I joined Witness three
years ago as the media technologist. um
where I am part of a team called
technology threats and opportunity.
We're looking at threats and
opportunities of emerging tech and our
entire uh mission at witness. We are a
30-year-old organization global human
right organization sits on five
continents and our mission is how we can
use video and emerging technology to
protect and defend human rights. And so
in that under that mission there since
2018 our executive director really
started to question what will be the
future of trust when we're thinking
about synthetic media deep fake
generative AI and my team started to
evolve and so we are looking at um
different aspect of how AI impact uh
election conflict gender aspect
non-conensual deep fake imagery uh and
really working along uh our communities
on the ground, human right defenders,
journalists, fact checkers and really
trying to support them. And what does it
mean to uh create and verify authentic
uh content in order to protect human
right evidence because we are in the age
where trust is being undermined all the
time. And what the tools we have to show
what happened to really um uh hold the
people accountable is through videos uh
audio visual content. So we have to
protect the trust of that. So, so
Shireen, walk me through a little bit
your perspective of what what does it
mean for for
the media audio and video to represent
to represent a reality with a certain
level of trust around it and then what's
happening in the world which is
beginning to undermine that. what you
what you said the executive director
back in 2018 said listen we have to re
we have to reconsider how we what our
relationship is with the evidence we see
&gt;&gt; uh so I will trying to break down your
question to two right uh the first part
can you repeat the first part
&gt;&gt; well this this what's happening in the
world of trust and digital media this
transition that we've been seeing what
what happened before 2018, after 2018
and how is this relationship changing?
Yeah, it's really interesting question
the relation to trust because I don't
think as a society we are still equipped
to really understand what is changing
and how the impact of a manipulated AI
deceptive AI on trust in general because
only the the role or the idea of AI
already undermine trust without even
using AI which um there are many lessons
to learn from early age of uh of media
in general that was manipulated from the
very start not necessarily using AI
right but uh something is completely
different right now with scale variation
uh the automation of it the
personalization of it things that we
haven't seen before uh that it's the
relation is still unclear what we do see
is what we starting and uh other uh
researchers defined it as like reality
apathy so we're starting to see this
overwhelming
uh for the public, the overwhelmed
public that's starting to just disengage
with the idea of like trying to identify
what is real or fake and everything
become fake uh in some ways. And we do
see how people in power are using that
uh uh notion of uh and the the easiness
of undermining trust. We see how uh many
people in power when they saying stuff
that they wish they didn't say or they
wish those uh conversation were not
leaked to the uh press they uh
immediately calling it fake right and uh
it started as a fake news type of title
now it's AI so we see this it's not a
new risk and it's not a new burden that
sits on journalists and fact checkers
but the scale of it is so overwhelming
and the techn the technical barrier are
starting to be very hard to um to work
around especially in the in the global
world.
&gt;&gt; So, and can you give me a picture of
over the last I guess since 2018? What's
been the this the how has this evolved
over time? So, it sounds to me like 2018
there's a big flag that was raised which
says okay deep fakes are going to or or
synthetic media is going to be a thing.
We need to account for that. We need to
prepare for that. We need to reconsider
how we evaluate and trust the media we
see. In reality, how has this actually
been impacting society over the last few
years? What what has been your your own
personal experience with that?
&gt;&gt; Yeah. So, definitely we see cycles of
hype around AI, right? So, we saw it in
2018, we saw it in the uh 2020 election
cycle. um and we saw it now what we are
starting to see is more and more the
impact of AI
and even now after the 2024 election
cycle global election cycle many people
dismissed uh the fact that AI played a
part but it's not true and we see that
as part of the deep fake oper force that
we are running there there are
again the scale is not many or hundreds
but it's enough for a really critical
contact to be manipulated in order to
impact the trust locally on a local
level. And we are not really paying
attention uh to to people that are being
affected the most in the regions that
are being affected because of uh um uh
fragile media ecosystem uh different
regimes and so on. Um so we definitely
see a decrease in that. We definitely
see a decrease in AI is being used and
we most certainly see around the globe
also in new as it's been a a big
research that came out in December how
uh uh non-conentual intimate deep fake
are targeting female mostly but uh we
see how it's targeting journalist human
right defender politicians and that
impact the way people can engage in the
public space the democracy uh space but
we saw that already happening in the
early days of uh of a defect generative
AI the non-conentual defect and that's
the main problem that we see it's a tool
to silence people um
um and then again going back into our
insight working really closely uh and I
will I will shout out to clarity of
being part of this force uh uh is that
we see a lot of audio manipulation which
is a very interesting type of trend that
we we haven't seen before so slowly
We're starting to see uh uh we saw at
the beginning more images and now we see
audio much more personalized content
much more interactive content and what
we also see is how the progress of video
can uh that we are witnessing in the
last couple of months really going to uh
step into into those spaces and and
create even more confusion in the space.
&gt;&gt; Makes sense. And he said something
before that I think is is an interesting
point that I would like to double down
on. He said you you you were mentioning
that there's these fragile media
ecosystems under different regimes which
have different um the the experience of
of how deep fakes are impacting them has
been ch has changed. Does that does that
mean that were you observing that
there's different places in the world
that have different values of deep fakes
and different deep fake types?
Uh I think due to lack of access to
media liter literacy access uh lack of
access to detection uh lack of
understanding of the technical
infrastructure there is a diff there is
a gap in access in general right and
that's already increasing uh not
necessarily the volume of AI but the
reaction to AI and then also the ability
of malicious actors to use AI uh much
more easily maybe less sophisticated AI
in order to really create a confusion on
the ground. So we did we did see much
more coming from the global majority uh
than we saw uh in the US election cycle
right because our eyes were on the US
but we just overlooking the people that
are being affected in that sense
&gt;&gt; and so what's the state of play today if
we had to look at you know the the day
you know today's you know the January
29th where where are we at with the
state of I guess deep fakes or synthetic
media in general in the context of of
trust online. How would how would you
describe the state of affairs?
&gt;&gt; Uh wow that's a really complicated
question
especially for people
&gt;&gt; why why why is it a complicated question
I think that's also worthy of a
response.
&gt;&gt; Yeah. Yeah. I think like also I'm very
zoom in so it's very hard to look at the
scale of the of the issue. uh which I'm
sure you can connect to that aspect of
like um
&gt;&gt; absolutely
&gt;&gt; yeah but it's also it's it's it's just
very complicated to understand the
relation of the impact of AI on us um
and where is it going I think we what we
are seeing also in the policy space that
we are at a point that we
we are we have the ch the chance to to
take to affect to affect the
infrastructure that is being designed
right now. And so where is it going? It
can be it can go to a very positive way.
It can go to a positive way that is
really thinking about public interest AI
and really thinking about uh the global
impact the global collaboration
partnership around the globes uh and and
really thinking about the risks uh of uh
AIdriven solutions in the global
majority as well in order to really
understand how it serves everyone.
um we are at that point that we can take
those decision and really change the way
uh policy regulation and therefore
technology advances are is being shaped.
Um so I feel it's like we can be in a
really good spot soon. uh it all depends
what steps we're taking. If we are not
taking any or if we're taking the step
that we're seeing right now of uh big
tech companies especially in the US that
are very publicly openly politically uh
decided this their side and which is
affect impacting a lot of other types of
circle of funding and resources
um we will we won't see we will see a
decline in trust right which uh uh we
already seeing on ax and other
platforms.
&gt;&gt; Yeah. So if you had to give your two
cents on what are the things that we as
a society should adopt and implement
over the next couple of years to because
it sound because it sounds like you're
painting a picture where this is sort of
this inflection moment where we have to
start crafting how how do how does our
digital infrastructure look like in
preparation of synthetic media and the
entrance of synthetic media? what what
are some key things that you would hope
to see from the industry over these few
years?
&gt;&gt; From our perspective, uh we are
constantly seeing the lack of people
from the global majority participating
in conversation in innovation space. Uh
so that's a major point how you include
and and collaborate with more people. Um
I think another point that we are also
working really uh extensively in witness
is how the impact of the infrastructure.
So how we really understanding the risk
for privacy, risk for accessibility,
risk for transparency and we really also
thinking on different solutions. So
there is a for example for deceptive AI
the way we are thinking about it is how
you uh identify what is real and how you
how you work on signals for what is
truth and how you identify what is fake.
And so um we are working on a a
standards development and really trying
to impact that space but also how our
developers and policy makers are really
looking at more exclusive equitable type
of standards. Uh that's will be where my
two cents
What about from a technology
perspective?
&gt;&gt; What do you mean?
&gt;&gt; For example, looking at authentication
or watermarking or or detection
solutions to be able to help bring, you
know, to surface some of the um some of
the credibility or the integrity to to
the surface. uh you you mean you you've
experienced now working with different
companies in that are that are looking
at digital forensics media
authentication from in different regards
what is your experience of that and how
do you see this moving forward
&gt;&gt; yeah uh it's definitely an holistic
approach there is no one solution um
detection is so critical we saw it in
the keep seeing it in the difficulty
response and uh responding to critical
high-stake cases
where uh uh implementation of watermarks
and on and provenence is still not
there. But then also when we are looking
even carefully uh how those two solution
are fitting to uh uh contextualizing
themsel in the broader uh skill set of a
journalistic process of factchecking
process uh and really respecting the
verification that already exist the
verification skill set and then also uh
as we are uh really deepening our work
in those uh areas we're really listening
to the gray area that those solution are
not going to work. So for example, open
source technology is very very
complicated and uh I'm sure you can you
have a lot to say about that but also
again going back to non-conentual defake
imagery detection
you know it's fake when you watch it and
it's still have such a huge impact. So
detection doesn't matter and provenence
doesn't matter. So how are we really
developing solution to a holistic
solution to work also across those gray
areas? Uh it's the it's a big question
and I think many many people are trying
to understand those uh those solution
and pro uh and step in that space but
it's complicated uh since uh for example
it have element of consent which we
haven't really dealt with before even
deep fake uh uh for adult uh content and
so on. So there there are more question
to ask and more solution to really
propose uh and to think about it as a
suit uh of solution not one.
&gt;&gt; I think what's on a lot of people's
minds is that there's no there's
obviously no silver bullet h for this
for this problem. Um, how have you and
so being on the side of the of the
person receiving a lot of the detection
responses and trying to piece together
the story, what's been h how do you
experience this no silver bullet type of
response when it comes to detection? So,
how how do you what's your experience of
when you have all these different mixed
signals and you have to deal with it?
How do you respond there?
Uh it's interesting because I feel the
frustration comes more from people on
the ground. They they need solution.
They need solution that are accessible
and easy to understand and uh um the
result. And so I hear a lot from
journalists and fact checkers the need
for okay give me a tool, give me a link,
give me something. And there isn't as
you said for me uh I feel like when you
have the when you educate yourself about
what is it uh when the media literacy is
rich in like educating
uh the public not on calling it
hallucination AI and not calling it
other types of like vague word that
doesn't mean anything to people don't
mean anything to people it's basically
you understand this is a datadriven tool
okay so let's let's understand how it's
being trained how it's been developed,
what the goal, what the mission, what I
was supposed to detect. And then I will
say if it's matching my content or not
and I feel like those uh those false
result, those inconclusive result going
to be much less frustrated to deal with
once you you have a really robust media
literacy around uh detection in specific
&gt;&gt; Shereim. What's been most um
what's been sort of the the your why
going through this?
&gt;&gt; That's a interesting question. And the
why?
Yeah. Uh it's hard to stand aside. I
don't know how to say differently. It's
like um
I can see how it can go well and it's
hard to see the the negative impact that
it has. Um
and it's also it's it just
um yeah it's a it's an abusive space in
many ways. So it's hard to not react to
it.
Well, Shireen, thank you so much for all
the impact you're doing and for the hard
work for the ecosystem and obviously for
the different populations that you're
supporting
within your work. And so it's it's a
privilege doing it together with our
very very very small part, but with the
leadership that you have there, it's
it's been really inspiring to see from
the side. So, thank you so much for for
for joining me for this short
conversation.
Uh, I really enjoyed it and uh, continue
the best of luck for witness.
&gt;&gt; Thank you so much, Michael.