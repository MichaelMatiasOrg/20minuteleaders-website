in in um last year u May 2023 the the
World Economic Forum released a
statement on on deep fakes and and
actually found uh uh the TLDDR under the
the title a bit a bit amusing. Uh so one
of the one of the bullets was uh experts
predict that by 2026 90% of all online
content will be synthetically generated
which is terrible. Uh and the next the
next line is we need to develop
detection methods for this. Um,
if 90% of online content is
synthetically generated, I can give you
a detector with a whopping 90% accuracy
in detecting synthetically generated
content today.
All it needs to do is just say that
synthetically generated is going to be
correct 90% of the time.
So, deep fakes are not really the
problem. You can't say that 90% of
everything, I mean, as cynical as you
want to be, you can't say that 90% of
all online content is wrong and I need
to be able to to tease out the the
remaining 10% somehow.
&gt;&gt; Hello. Hello, Tal Hassner. Thank you for
being with me. uh the human zero day, a
series which I've grown to love so much
uh because over the next short while
we'll be speaking about something that I
became increasingly passionate about and
I think everybody that's that's sort of
here with us right now is are are
getting really interested in
thank you so much for being with me.
&gt;&gt; Thank you for having me.
So Tal um it's hard to introduce your
background because uh your background is
is quite incredible not just because
you're a scientist by training uh right
with a PhD in applied mathematics and
computer science from Whitman Institute
but you've applied
yourself as a research scientist in
numerous different capacities at some of
the obviously most successful companies
in the world. And you've also taken part
in building a lot of core foundational
systems which we rely on to to act on
our in our digital landscape and that
speaks to our digital identities and
biometrics
and growing with the field also with
also in the context of the way that
generative AI is impacting digital
identities. And now most recently,
congratulations on being installed at a
startup. uh and so you you're really
taking the whole the whole system end to
end and but seriously thank you very
much for taking time to be here.
&gt;&gt; That's my pleasure. Thank you for uh
inviting me.
&gt;&gt; Tal, how did you and I forgot to mention
small note that you also sit on chairs
of numerous different organizations and
you effectively help review some of the
most cutting edge literature in the
computer vision space. But Tal, what got
you into this world of computer vision
and specifically maybe even identities?
How did you find yourself there?
Uh, I was actually thinking about that
uh the other day. Funnily enough, my um
the the deci the decision to to go into
computer vision
um
I made that decision before computer
vision was popular. Uh, at the time it
was almost theoretical.
Um,
and I made it, funnily enough, because
of a deep fake, or at least
what we would maybe consider a deep fake
today. This was back when when deep
fakes uh was not a term anybody was
familiar with. Um,
&gt;&gt; do you remember what it was?
&gt;&gt; Oh, yeah. I remember exactly that. So,
uh, I just started my my graduate, uh,
my my my my graduate studies. Um, and
when you do that at Whitesman, the first
few weeks, you get to, as a student, you
sample these different courses, trying
to get the lay of the land, trying to
see who you connect with, what sort of
professors you resonate with. And
there's a lot of interesting stuff uh
theoretical computer science complexity
ma different types of mathematics but uh
but it was all sort of
maybe I don't I don't want to use that
word but a little dry but and then I was
sitting in in very tired at the end of
the school day in a classroom uh waiting
for the beginning of a new lesson and
this young professor,
very energetic, very charismatic. Uh,
this was back in the day when if you
want to show a movie, you had to like
push in a card, like a big television
with a VCR underneath. So, she was
pushing that in front of the classroom
and she was pressing play. Um, and she
was showing a video, black and white
video, grainy, of uh, just herself.
Don't worry, this is sort of a mic drop
minute of herself walking through a
computer vision lab a lab a lab with
computer people sitting tables by the
screens.
It was just the camera tracking her and
then she paused it and said uh and now
um I ran some processing. This is
computer vision. This is what computer
vision can do. and you pressed play
again. And it took me a few seconds to
realize the difference between the first
video and the second video because it
looked almost the same. Second video
just didn't have her in it. So, she was
gone from the video including her
reflections, including uh she sort of
made herself disappear uh in our neck of
the woods. Uh this professor this
professor Mikallani from Whitesman
Institute and that was called
disappearing Mikall video.
Um, and I was looking at that and
thinking, "Oh, that I want to do that.
That looks really, really cool." So,
that actually started uh my my journey
into uh computer vision. Uh identity is
something that happened a while later.
&gt;&gt; Wow. Okay. And and when was this grad? I
don't want to date you, but I have it in
front of me and I and I do think this is
important because deep fakes are often
associated with a 2017
Reddit thread.
&gt;&gt; No, the uh it was actually if you want
to associate it with a 17 number, I
think the right 17 number is 1917, which
I think is when the um I think it was
called the Kakongi Kongi fairies um uh
story came out. Uh but to your question
uh this was in 1997
or eight I guess.
&gt;&gt; Incredible.
&gt;&gt; Um
&gt;&gt; incredible.
&gt;&gt; Yeah. So people have been manipulating
media long long long before
um deep fakes. Ever since people were
able to to capture media, it's been
manipulated and for any of the reasons
that you're seeing for all the reasons
that you're seeing today.
&gt;&gt; Absolutely. Wow. And then obviously the
the world over the last two years took
many existing problems and uh
exacerbated them also took some many
existing problems and and starting to
help solve them which is which is also
amazing. Um, and tell me a little bit
about your your journey in in your
actual implementation of your technical
skills in the real world in real world
scenarios because it feels that a lot of
the work that you did, especially
recently, I guess from about 2018 or so,
has been really in cornerstone
technologies that are now servicing many
other technologies in the context of
facial recognition and identities.
So the I don't know if there's a a
particular
switch or change or or milestone moment
that I can point at. This was uh a
gradual progression. I started working
um um on on problems related to face
recognition seriously in about 200 2008.
This was with uh Leure Wolf from from
Tel Aviv University. Uh
and uh at the time uh um cutting edge
mean
benchmark a new problem came out for for
computer vision which was u
very intriguing for us at least. Uh this
was the label faces in the wild
benchmark uh which uh anybody that's
been doing face recognition in the last
decade knows very well and it was
revolutionary. Um I don't I don't know
if people today understand just how how
revolutionary it was. Um
up until that point
there were already a lot of face
recognition work being done and there
were studies
federally funded studies that were
showing that computers were already
doing better than people in recognizing
faces. that all those studies used
photos of people which were obtained
under what I call biometric uh
circumstances or controlled or
constrained circumstances. So this would
be a person standing in front of a
computer or in front of a sorry a camera
and and wanting it to recognize them.
They're participating with a recognition
system. um they take their glasses off,
they put on a stern face and they look
straight at the camera. And in those use
cases,
computers were already doing better than
humans in 20067.
But then label faces in the wild came
out. label faces in the wild was the
first big benchmark uh as far as I know
at least to to to challenge computer
vision systems with photos of faces that
were in the wild. So these are photos
that were taken in in
for media purposes, sports, uh
publicity, whatever. This was scraped
photos
and
none of the methods that were performing
the methods that were performing well,
the state-of-the-art methods that were
beating humans at the time, they
collapsed. They just couldn't handle the
the variability, the appearance
variability. Um,
and that's when we started looking at
this. This was the the 2008 was the
first time that we got involved in this.
This is the first workshop on able faces
in the wild. Um
we we got very good uh results on it at
that time and and from then on it was
just a it was just a progression from
one paper to the next from one system to
the next. In 2018, AWS
uh reached out and um I think the way
they described it is we want to
commoditize face recognition
and um and yeah, that was the switch
from from academia to to from from doing
this for papers to doing this um in uh
uh for a product. and and what what was
that like for you transitioning from
very deep technical research to doing
that same thing but now needing to
productize it at the end and having
customers in mind.
&gt;&gt; Um
so uh first of all there's for someone
who's been in academia for many years
the the move from academia to industry
is is not always easy. It's it's a
different environment but I but this is
on the the
call it organizational
&gt;&gt; right
&gt;&gt; organizational aspect of which which
looks different.
&gt;&gt; Um one of the things that you notice
immediately is that in in a lab you're
typically
you're typically a one-stop shop that is
just you. If uh there's no one's going
to collect your data for you. There's
there's no one going to to vet anything.
This this is just you. Uh when you're
working in a in a an organization
uh certainly AWS or later um Facebook
um one of the organizational changes,
one of the psychological changes that
you need to get accustomed to is you
have this massive support around you
that can um
that can that can power multiply.
Um and this is before we start talking
about the resources that you have in
these places. Uh the data, the storage,
the processing power, things that in
academia would be
science fiction um in in many cases. So
yeah, it was a it was a big difference.
It sounds like also just a big
playground for experimentation and
research, especially not just the
financial side, but the the actual
ability to scale with the the data that
potentially only this organization would
have, you know, transitioning the the
conversation to to a little bit of your
work at Meta. I'm sure that there you
know you're seeing similar similar
impact of application of research but in
a in a totally different world right
so the products in AWS were products
that was the main product was was a um a
face recognition um a service that that
people can use at Meta
&gt;&gt; famous AWS recognition
&gt;&gt; yes um at at meta this was the the
um
the face recognition um the face
recognition probably at the time it was
a tag suggestion product and and um
&gt;&gt; I use that product quite a bit myself.
Yeah.
and um and the OCR and both of them for
very different reasons both of them the
idea that this is something that's
running I mean if you think OCR um
optical character recognition this is
taking us a little bit away from from
biometrics but I it's just a an easy
example to to um um
uh
so we're talking about a system that
needs to be able to detect and recognize
text in any language that um
Facebook has users understanding and
reading. It has to be scalable and it
has to be um fair uh or at least um um
equitable. So you need to be able to
process or to deliver the same sort of
level of of accuracy for languages which
have um
Latin character sets uh as you do for
thousands of pictograms in in um in in
Chinese
um
and uh and and then you have questions
of where do you get the data and then
there's a questions of of how do you do
this responsibly because there's
regulations
um and and how do you maintain that? How
do you do that efficiently?
And
we were my job was was uh was was just
to develop the to be involved with the
technology itself with the OCR
technology itself. But uh there's
downstream use cases for OCR which uh
which could be very very um influential
from a societal perspective.
&gt;&gt; How so?
&gt;&gt; I don't want to talk about specific uh
products at uh at Facebook. But you can
imagine the the the
uh importance of being able to recognize
text and images for various um
&gt;&gt; for for for various uh even safety
applications.
&gt;&gt; Sure. Exactly. Absolutely. Well, T, I'd
love to transition for a second to the
world of the security aspect of of the
space because this is it's the human
zero day. are looking at also um not
just the technological advancements in
the space but also how these
technological advancements are impacting
the security vulnerabilities that we as
humans have in our day-to-day. This is
relevant for both, you know, democracies
and as well as for organizations and
enterprises and our ability to to do
what your professor did 1997 or 1998
today in a commoditized way. It's a
pretty alarming one, but it's only one
example where, you know, potentially we
can misuse technology to trick and fool
somebody to doing something they didn't
mean to do. And in that case, for
example, it's the use case of a of a
deep fake impersonating somebody. In
many other cases, it can be, you know,
simple, you know, simpler social
engineering techniques. But since this
is a you are coming from a very
technical background and you've actually
had a chance to hands-on not just work
but but publish really cool papers and I
got to check out some of them myself. I
I'd love to hear a little bit about your
experience in thinking through what are
ways in which one may be able to keep up
with with what's happening on the
generation front in the detection space.
It was hard to keep up with the
generation for just in the generation
space let alone with the defection space
uh in in in uh um in recent uh months.
Um so so
first of all the the problems the the
risks with deep fakes. Again these these
are not new by any stretch of uh this
this um this goes back long before there
were um uh computers doing uh deep
fakes. Um there is maybe a difference in
in how accessible these tools are today.
the quality uh of their output and maybe
more importantly though you that's
arguable um um the the channels through
which they can be distributed. Um
so with all that that maybe makes this
problem bigger but um but let's let's
talk about the problem. Let's talk about
what is the the problem. Um
in in um last year u May 2023 the the
World Economic Forum released a
statement on on deep fakes and and
actually filed uh uh the TLDDR under the
the title a bit a bit amusing. Uh so one
of the one of the bullets was uh experts
predict that by 2026 90% of all online
content will be synthetically generated
which is terrible. Uh and the next the
next line is we need to develop
detection methods for this. And
if 90% of online content is
synthetically generated, I can give you
a detector with a whopping 90% accuracy
in detecting synthetically generated
content today.
All it needs to do is just say that
synthetically generated is going to be
correct 90% of the time.
So deep fakes are not really the
problem. You can't say that 90% of
everything, I mean, as cynical as you
want to be, you can't say that 90% of
all online content is wrong and I need
to be able to to tease out the the the
remaining 10% somehow.
Um, so the simple question of of uh is
this media item
synthetically generated? Yes or no?
media item could be image, video, audio.
By the way, even even text is a in some
sense a deep fake and I'm looking at
you, chat, GPT and claw, but those are
also deep fakes. Those are also
synthetically generated and everything
I'm saying mostly most of what I'm
saying relates to those as well. Um
if if um just looking at the question of
looking at one on a media item like that
and saying is it yes or no synthetically
generated not really interesting in a
world where 90% where everything is.
So the actual questions that um that
that we're asking the actual questions I
think are are interesting to to to try
and solve
like maybe
broadly can be categorized under three
uh three labels.
One would be providence methods, the
other would be attribution methods and
the third arguably the most important um
is integrity methods. Um
and um
and so when you're trying to solve these
problems,
those three categories
are where you want to look for your
solutions depending on on the product,
depending on what you're trying to solve
for. just to maybe explain what these
things are. Uh
&gt;&gt; please.
&gt;&gt; So it's not just abstract
&gt;&gt; please.
&gt;&gt; So so provenence is tools, methods,
technologies that allow you to trace the
lineage of of a media item back to its
um uh to to verify
trace and verify uh the lineage of a of
a media item back to it source. So,
think about maybe a a painting by um um
Renaissance artist uh being sold in an
auction house today. When they sell it,
they show the signature of the artist on
the painting and they show maybe
documents that uh um that that prove how
it was or or that the document how it
was um uh exchanged hands over the years
going all the way back to the source.
That would be provenence. the ability to
be able to show this is where this item
came from and this is why in digital
form that takes uh that looks like
watermarks and in that sense the
artist's signature on the painting is a
watermark. This is an artist's watermark
on the painting.
Um
it could be invisible watermarks.
Uh, invisible watermarks are tiny
changes to the pixel values in an image
which you wouldn't be able to tell
happened. And we see the image before
and after these changes were made. Um,
and you wouldn't be able to tell the
difference. But um, but a computer would
be able to tell the difference and would
know just by seeing those changes
that this is a signature, an RS
signature that this came from a
particular source. There's other methods
of doing providence. Those are just two
examples. Uh maybe the simplest form is
just adding metadata. Uh but that can be
manipulated easily. So maybe not a very
effective uh provenence technique.
The second which I've recently done some
work in is attribution.
Going back to the artist uh Renaissance
artist example, let's say instead of uh
auction house um uh selling this and
giving you documents, you discover in
your attic a rolled up parchment with uh
with an unfamiliar painting
and with no signature. You take it to an
expert and the expert looks at the brush
strokes and looks at the colors and the
composition and the and the expert say,
"Well, based on all that, I can
determine with 90% accuracy that this is
this artist that did this work. Um, this
artist painted it." So, you don't have
that lineage, that tracing, but you do
have that analysis that that estimates
who this where this cames from. That
would be attribution.
Again, in digital form, that would mean
um looking at a at an image and
that you just downloaded that that was
just posted online and being able to say
something about where it came from. So,
not just a yes or no question, but um
but who or what generated or created
that image?
Um this is not a new field. Um so in
painting of course people have been
doing this. There's been artists have
been um art experts have been doing this
for a while. But you can do this and by
taking a an actual photo and recognize
the camera model that it was that was
taken on. And you can do this by taking
a generated image and recognize the the
AI model that um that that uh produced
it. So that's the second um type of
problems attribution. Uh the third again
arguably the most important for security
most important for societal uh impact uh
the most important if if you want to try
and solve these problems I think in my
opinion is integrity
integrity means all the different
technologies all the different uh ways
that you can take an image analyze it
and ask about the content if it's okay
yes or no
Okay, here means is it violating laws?
Is it whether these are whatever laws
the could be IP laws or could be um um
uh explicit material uh laws um and so
forth. Is it um um does is it a picture
of counterban? Is it a picture of um
hate speech or misinformation? Analyzing
the image and trying to answer those
questions. And the reason I think is
important is if you have a photo of
something horrible,
you know, that someone spreading on on
the dark web,
do you really care if it was a photo
that was taken with a camera or a
realistic photo that was generated? It
is horrible one way or another in you
honest that's what you want to try and
and protect against the question of
whether or not it was generated who
generated it and why always a secondary
I think to recognizing that there's a
problem with this image for however you
want to define problem for your security
application for for your in your
context.
This is this is fascinating. Tal, do you
think that the that you're that the way
you're describing the effectively four
four solution spaces, right? So I heard
I heard uh provenence well well I get
there. So provenence, watermarking,
integrity, well provenence, attribution,
integrity, and then detection as a non
as a non-solution.
&gt;&gt; Yeah, it's it's all really interesting.
I mean, again, if you know that this is
that this is a bad image for whatever
reason, bad could be um child
pornography or it could be just someone
violating your IP and using your logo.
It doesn't matter what you're looking
for, but not that I'm equating those
two. I'm just saying
&gt;&gt; course
for you.
&gt;&gt; Do you believe that that is applicable
that this assessment is applicable to
both the online misinformation
disinformation space as well as the
enterprise cyber security defensive
systems?
um is that would would is the same your
same assessment of solution spaces be
equally applicable to both situations?
&gt;&gt; I think so. Yeah. Um again, if it is
bad, you're trying to recognize if
there's if the person you're talking to
uh is not who they say they are, doesn't
mean that you care if it's AI or um a
very good impersonator. So, so you say
let's verify, let's look at the
verifying the identity or the device as
the fundamental layer and if it's from
the verified source or that's the main
question or not,
&gt;&gt; right? As a as an idea.
&gt;&gt; Yes. The yes or no is this fake? Um
we're very very I I I I wouldn't be
surprised if in the next few years um
there will be readily available and
commonly used technologies that uh would
make uh this conversation for example
this exchange for example very very
natural but without us actually being
here and it will still look real and be
acceptable and everybody will be fine
with it. So
&gt;&gt; yeah, I think Notebook uh Notebook LM
did with audio just recently, right?
&gt;&gt; Yeah, exactly.
&gt;&gt; Yeah.
&gt;&gt; So I don't really care if they're um
real or not real. Many use cases for
notebook most I would want to hope that
all use cases for notebook LM are
legitimate and you're listening to it
and it sounds so do you really care if
they're real or not?
&gt;&gt; Sure. Well, so Tal, I'm I'm curious. um
you you well you've been in this space
for a while. You also had you also did
have a chance to work on detection
technologies
um and in in the context of deep fakes
even regardless of whether it's a it's a
real good solution to a from a business
question because that was the discussion
we had. Now I'm curious to hear your
perspective technologically on this
because one of the big things I've you
know we read every day and that CISOs
are highly concerned with are this is
this seems like a big arms race. We've
seen the antivirus approach take place
in semantic and Norton in the year 2000
with malwares.
Are we facing, you know, is this going
to be just a, you know, a a replicating
malware 2.0 or antivirus is going to
keep up? How do how should we think
about this technologically?
So again going back to the three
categories then it's it's more a
question of uh not necessarily a
question of of how can we keep up with
the with the deep fakes. It's more a
question of how can we keep up with with
particular types of media that we don't
want being spread again regardless of
whether or not they're
&gt;&gt; um um faked. Uh, and by the way, fake
does have an influence on it does make
those problems more challenging. I mean,
you're seeing
I don't know if you saw them. I'm sure
many have these photos online where it
looks like I don't know natural building
with some trees and forests, but if you
squint your eyes, you actually see a
face or you actually see something. Uh
so
that's already start people are already
starting to use that in order to spread
some very troubling u um messages and
and AI in that respect makes that
easier. It's a lot easier to create an
image like that with AI than it would um
staging it in real in real life. Um, but
that's an arm race between not between
fake detection methods and and and
fakers. That's uh an arm race between
uh uh uh people who were trying to
to people organizations were trying to
to to spread uh bad content. again your
definition of bad um versus those that
want to for whatever reason block this
this bad content um and that's a very
old arms race that that has nothing to
that hasn't uh again
&gt;&gt; generative AI makes things easier for
the other side and it makes it more
challenging
uh to detect those images I was talking
about OCR earlier so in OCR um um I
don't want to give anyone any ideas, but
if but you obviously if you have like a
mean photo with a text clearly written
in it, that is much easier to recognize
that there's text in the image versus
different ways that you can maybe make
it harder for a computer to to
understand. Again, not giving anyone any
ideas, but uh
you could do that even before generative
AR,
&gt;&gt; right? That makes sense. I think I'm
asking on the I I had a I have now some
experience in the world of in the world
of detection.
um in fact have spent great time and
energy understanding detection by the
way not because I think it's the right
solution but because when approached
with and challenged with the same notion
of can we check whether this person
we're talking to in a business setting
is real or not or is this the person we
want to be talking to the solutions in
place for provenence attribution and
integrity
are just not there yet. Right? There's
there's there is infrastructure to be
built for that. And there's great great
organizations like the C2PA for example,
which I very much appreciate the the the
the way that they're generating momentum
and and so I'm looking still at this
next year and a half and I'm asking well
if over the next year and a half people
are scared that they will be the next
social engineered human in the context
of hiring a North Korean spy for their
HR team or erh or sending money when
your CFO didn't ask you to send money or
you're the IT support for MGM Grand and
you're about to give away that that VPN
access to your colleague. I I mean then
then then what what can we do in this
next year and a half?
&gt;&gt; I I I I don't want this to be understood
as though I'm saying everything that you
just said is not a problem. It is
definitely a problem and that problem is
growing and deep fakes are making that
problem in many sense or changing the
way that I mean I gave the example of of
um those images where you squint but
with the example of of u someone uh
calling you and and um you think you're
talking to the CEO of your company but
it's actually uh
that problem also existed before before
you'd need to hire a very talented um
impersonator and now you can do so it
hap it was a problem before. It was
something that you needed to address
before just now you there's more people
that have more access to this and so you
need to evolve the the solutions and and
and and evolve the technologies in
place. But just asking is this fake or
not is not necessarily how you solve uh
how you solve that. um
you have more um I don't know if more
but you have KYC systems for example
which can can help you verify that
someone is who they say they are. Um,
maybe you need to install more, not that
I'm promoting anything, but maybe you
need to install more KYC
um, uh, check know your client or
customer um, um, uh, checkpoints to
verify that the person that you're
talking to is the right person. So that
CEO CFO interaction
maybe that could be solved with with
better policies, internal policies on on
what the the CFO needs to be doing
rather than um uh detection methods. And
I've heard that is a very real
very real practical notion amongst
security professionals asking well if we
had the right process in place no deep
fake could harm us because even if they
did get away with a deep fake then the
right process in the important workflows
wouldn't let the bad things happen
because nobody should take we should we
should exercise effectively a zero trust
policy when it comes to to perhaps the
sensitive in these informal
interactions.
&gt;&gt; Um
look, you gave the example um of very
apt example of of um um the virus
antivirus arms race. Um I I know
organizations where they have very
strict policies on what you can or
cannot do within the organization so as
not to expose the organization to to um
to viruses. Um regardless of whatever
antivirus firewalls they have very
strict policies. You cannot for example
connect an external device via USB to
any of the computers inside the network
for example. um that
policy effectively uh if followed would
effectively stop viruses from coming in.
It's not a technological uh antivirus
firewall solution is maybe a boring
solution but it's a very effective one.
Um I don't think it's a one-stop shop.
Um it's a one solution kind of for
anything, silver bullet for anything. I
think in some cases it's enough to have
a policy change. and others um you need
to do something more subtle. Um others
you may need KYC systems and KYC is
technology that you need to develop and
and attribution provenence integrity
method these are all technologies that
need to be developed and under
attribution by the way there's a lot of
work in analyzing deep fakes. So this
this is not that I'm saying uh no no the
solution that's someone else's problem
solve it with policy that's that's not
my message. I'm I'm saying it's it's
more nuanced than than than just is it
fake yes or no.
&gt;&gt; Absolutely. I I I I completely agree
with you and uh Tal we can I have so
many more questions to ask you and so
many more topics to talk about and uh I
really want to thank you for taking the
time to be here with me. Obviously
you're you have you've been
&gt;&gt; well effectively you've been looking at
the space for about 25 years. So uh I
guess it makes sense that you're you
have some very strong ideas and and
opinions about also how the world
operates in the context of of of this
and and and going back I think that most
fundamentally you're absolutely right.
This is not a new problem right the the
the problem of deep fakes or or
manipulated content is not new as it
pertains to human security. I think that
what is new is potentially the level of
accessibility and the rate of change.
And so I think that potentially from a
security perspective, many look at the
threats and are saying, "Whoa, this is
new. I haven't had an employee tell me
that they spoke to a candidate which
never existed." This is
&gt;&gt; the world the World Economic Forum
statement from from last year. One of
their other findings is that in 2022, so
we're talking about what two almost
three years ago, 60% of cyber security
experts um were already reporting uh
deep fake
um attacks, deep fake security attacks
on their respective um uh organizations.
So that's uh before Flux and Sora and
and the stuff that you have uh rake out.
So yeah, you're right.
&gt;&gt; Absolutely. Tal, thank you so much.
Really appreciate your time.
&gt;&gt; My pleasure.