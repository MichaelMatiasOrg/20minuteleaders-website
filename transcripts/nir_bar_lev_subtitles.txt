1 Nir, how are you? Good. How are you, Michael? Fantastic! Thank you so much for joining me on 20 Minute Leaders. It’s already nighttime , obviously, in Israel, so even more thank you for taking the time to join me. No worries. Standard working hours. Standard working hours for a CEO of an early stage start-up. That has to, obviously, do both US and Israel. So wonderful. You know, Nir, so much experience in the machine learning  and artificial  intelligence space, research and from Google, and most recently, the company that you founded, Allegro. And I love to use this next 19 minutes or so, so that I can learn a little bit about where we’re headed. And a lot of the people that are viewing this, some of them are technical, some of them are not. So, I’m sure we -- Let’s try to find a balance of how can we talk about this industry at a bit higher level and what opportunities are... and what opportunities are and what the constraints are. Sure. So, tell me a little bit about Allegro really quick just so we can have context of what you’re interested in and some of the things that you’re researching. Absolutely. Actually, we do a little bit of research, but -- I mean, this is also on team communication and building... - building models that's -- yeah. - Sure. Sure, sure, sure. I mean, research always has a specific foundation in AI. - Yeah. - But basically, where we come at it or -- We’re about engineering the research and I’ll explain. So, the thing about AI -- and when I’m speaking about AI, in my context, it’s machine learning and deep learning. Basically, it’s a fundamentally different paradigm on how to do software. Right? So, traditional software is a very logical, linear development process. At its essence, it’s basically engineers building algorithms to solve problems, and then coding them in a way that a machine understands, so then, a machine can actually run it. Whereas in machine learning -- deep learning, what you’re actually doing is, you’re employing algorithms to come up with the algorithm to solve the problem. - Right. - This is -- And so, you do this through a process of iteration and experimentation, hence, machine learning. Right? So, the algorithm supposedly learns, right? Yup. And so, this is a very -- this is an experimentational process rather than a standard software process. And this has fundamental implications on everything else. Right? On the type of talent that you need to basically drive development and maintenance of this, on the type of tools that you need, and how to integrate workflows to make that work. And so, what we do at Allegro is we basically provide an end-to-end tool chain or platform, whatever you want to call it, that basically supports the key pillars or aspects of AI around the paradigm so that our customers can focus on building and maintaining their product or service, so that they can focus on -- and therefore, build a better solution, faster, more cost-effectively. Right? At the end of the day, we’re about engineering the processes that are specific to AI to make it more productive. Okay. So, maybe give me a brief context and a rundown of what is the life cycle of an AI project in terms of, let’s say, that I now -- I want to take a team of three other researchers and engineers. I want to solve my problem. It’s that I want to know -- I want to know what my dog is going to think next. Okay? So I have a new puppy. I know that he has patterns. I just don’t know what they are, of when he’s going to go bite the couch. And it's awful because I’m going to have to pay for this couch, - because this is a rental. - Right. Right. So, how do -- what is the life cycle of such a project from a machine-learning researcher’s perspective? Actually, you hit the nail on the head, right? That’s one thing to remember for the non-technical audience, right? In a machine learning AI and deep learning, it’s not a solve-all solution for everything. - Right. - It’s really about being able to identify patterns in lots of data or complex data and being able to come up with predictions as a result of that. Right? So, you hit the nail right on the head on that. And so, being able to understand when your puppy is going to bite the couch, you’ll need to collect data. Right? To basically -- You’ll need to collect data about the puppy’s behavior. Right? For a period of time during which he may bite the couch or not, and he’s just acting around. Right? So basically, in this case, you're probably going to film him. - Right? - Yeah. You could theoretically also put some sensors around him and measure other types of things related to, maybe, his level of anxiety or whatever, - and blood pressure, right? - Or I should follow him around, so I can write logs of every single thing he does. Exactly, right? And then so, basically, that’s the first thing you need to do. I mean, because data -- what we’d like to say is it’s really the raw material that drives the process. - Right? - Right. And so then, what you’re going to do is you’re going to have to basically -- you’re going to have to have a data scientist or you’re going to have to find someone that is going to figure out, "Okay, what is the best... the best way to address this or to build a solution to predict this?" And what I mean by that is you want someone to be able to identify, "What’s the right algorithms?" There are a lot of algorithms out there, right? In deep learning, they’re called neural networks. In machine learning, there’s a set of algorithms. But which is the one that’s best suited to solve this problem? And there are obviously different types of algorithms, each one for different solutions, optimize for them. And then, you’re going to have to basically build an experiment. You’re building basically an experiment where you’re saying, “I’m going to take this data. I’m going to assume this is the right model for me. I’m going to tune different parameters around it.” You have some -- think of it as a block where you can actually tune and change some levers. And then, you’re going to run an experiment and you’re going to see the results. And I just -- I want to also -- There is a differentiation because I think there’s a misconception that anybody who says, "I’m a machine learning engineer," or something like that, then people assume that they’re a mathematical genius, that they’re sitting and they're -- they’re creating the -- they’re necessarily creating these new, unseen-before algorithms. But a lot of engineers, that are already working on machine learning -- today, you have all these democratized tools, like Tensorflow and PyTorch, and all these out-of-the-box tools where you can -- even if you don’t know machine learning at all, you can say, “Yeah, I have this data set. I heard on the podcast that this should be suitable to a logistic regression. So, let’s just try it out,” and 'Oh, it works' or 'it doesn’t work.'" It’s true. So, a lot of the big plat-providers, namely, mostly, you see Google, Amazon, Microsoft, and some others are providing tools that enable people who have basic technical affinity to be able to do these things. But the important thing to remember, at least, where I’m coming from in the industry, is that these tools are lowest common denominator. They’re going to be able to maybe solve a problem of a puppy. But once you get into situations where the precision becomes much more important - because - Right. the cost associated within a stake is going to be bigger, say, autonomous vehicles, right? - Yup. Yeah. - Or something else, right? Then, it’s not enough to have a layman using these tools. You’re going to have to actually have people who are much... much more knowledgeable, both on... on different aspects of this, right? So, there are a lot of aspects. There are the people who are actually going to to use their neural networks and to do these stuffs, and maybe even tweak them around, and even -- We are working with companies who even are smart enough to actually be able to build their own neural networks. Yeah. To them -- engineers who know how to actually take that and build a solution, that's scalable solution, right? And so, there are many -- you need to have a lot of professionals in this process, right? - So, it depends -- - It really sounds like the -- It really sounds like the 80-20 rule, where you can get 80% precision with 20% of the effort. But if you want to get a 100% accuracy, and you want to make sure that your autonomous vehicle is going to be predictable in these circumstances, you’re going to have to put 100% of the effort and go that extra mile. Did you take a sneak peak at some of our presentations? - Because – - Oh, no. I – that’s exactly right. You know who I grew up with. And I’ve been hearing about this from Berth, basically. [laughs] Yeah, it’s exactly that. I heard somewhere, and it's so true. I mean building a prototype -- even building actually a prototype of an autonomous vehicle to drive in a parking lot is very, very easy. The problem is exactly that, to build a real product. That’s exactly the 80-20 rule. Wonderful. Okay. So, Allegro, how is that helping either democratize machine learning and AI so that others can use it, or make it more efficient and better for teams? How does this whole process work? Sure. So, we basically -- we help companies in three or four pillars. Right? The first one is what we call experiment management or process management. And this is really around how do you manage these different process of experiments? - Right. - Right? So, you have a lot of experimentation that you’re doing, and you need to basically be able to pick and choose the best one, compare them, go back and maybe take a different direction in your research, et cetera. So, how do you actually manage that process efficiently? That’s one piece that we do. The second piece -- and I’m going really fast, high level here, right? The second piece is around this new space called MLOps, right? So, it’s the AI version of DevOps, right? And DevOps in a nutshell, it’s about taking a single, discreet piece of code and scaling up over a lot of computers so that it can work and scale, right? To service a lot of users or what have you. Whereas, in AI, you’re actually having lots of different experiments running at the same time. And so, you need to have -- The problem is different. You need to have a way to scale up lots of slightly different pieces of code. They’re about the same, but they're slightly different. And it’s a different problem. The other thing is DevOps usually happens in production. And so, in standard software, there’s a very clear delineation between development and production. Right. Whereas, in AI, the need for a lot of compute power begins really, really early on. - Yeah. - As you -- know, right after you built the initial modelling, you now have to take more compute power to do bigger, bigger data sets. And so, this is the area of MLOps. And so, it’s a very different problem than DevOps. And we provide a really simple solution for that so that companies who have data scientists can self-serve themselves because that’s, oftentimes, where the problem is. They’re going to the DevOps who don’t know exactly what they need, and there’s a lot of friction there. So, that’s the second thing that we help with. - The third thing – - You actually -- You actually own the GPUs and you manage the running or are you --? How does that actually work over there? Right. We don’t own the GPUs or any of the underneath hardware. Our solution is 100% software. Okay. We basically provide an orchestration and a queuing layer to enable data scientists to do this. It can sit directly on the hardware. It can also sit on scalable solutions like Kubernetes, which were built for DevOps. But a lot of companies who have this want to have their AI also on that. So, we basically have this kind of like translation layer so that the data scientists can build solutions easily. And it then runs and it kind of runs ultimately on Kubernetes’ [UR] system. Yup. So, that’s the MLOps part of it. The third pillar is around data management. And what I mean by data management is really metadata management. It’s about the insights of the data. Like, when you’re looking at data, think about your dog, right? The video itself is meaningless unless you basically say, "Okay, here’s where your puppy bit the couch," or "Here where he started playing around," or whatever. That metadata, maybe, it’s nighttime or daytime, or it's winter, right? Those are the things that actually potentially could affect your puppy’s behavior, right? And so, those are the things that you need to manage. And the thing is that you need to understand data skews and data biases, because ultimately -- Let’s take an example from autonomous vehicles. Most of the time, what you’re dealing with is these really rare edge cases. What happens when you’re driving and the sun is exactly shining through the camera, and you’re making a left turn, and someone’s coming from the right, and there’s a stop sign, whatever -- those edge cases are the ones that you need to deal with. And they’re rare. And so, you don’t have a lot of data on that. And so then, what happens is, actually, if you have too much data of something else, and not enough of these situations, your neural etwork, your algorithm is not going to learn well. So, you have to rebalance the data, et cetera. So, building a solution to do that, to really manage metadata as raw material for your process, this is something completely new. Companies like Google, Microsoft, Amazon have internal in-house solutions built for that. But 99% of the other companies don’t. - Right? And so -- - And they want to -- almost every start-up either claims or actually does AI work, yeah. Yeah. We can talk about that at a different time. I mean there are some amazing startups out there but you’re right, a lot of unsubstantiated claims are also out there. So that's the third one. It doubles your valuation within a second. So, of course you do. And then, I guess the fourth pillar is about collaboration. And it’s really -- It’s about collaboration and actually efficiency of your human capital. This has multiple facets. So, the first facet is your data scientists. Really good ones, again, we talked about the fact that we’re solving problems for companies who have very high standards, not your layman solutions. And so, getting these very -- highly qualified research scientists and data scientists, super expensive and very hard to find. And so, if you have them, you want to make sure that they’re as productive as you can. The second thing is researchers and data scientists have a very different mindset than engineers. Yup. Because, again, they’re doing research work. But ultimately, you’re building a product which is an exercise in engineering. And so, there’s a friction there. And the idea is how do you actually make them or how do you actually get them to integrate well into a larger product and engineering team? So, obviously these have a lot of aspects around how do you manage it organizationally, et cetera. But it also has an aspect around tooling, right? For example, how do you make sure that you have  a tool that enables a simple hand-off between something that the data scientist build and engineer can actually take and use as containerized solution that they don’t need to understand what’s inside. So, we facilitate those things - Interesting. - from that aspect so that, on one hand, data scientists can become much more productive, but also at the same time, be able to hand off and integrate nicely into the large organization. So, those are the -- I guess four pillars of how we help companies. Wonderful. And where is it at now? So, Allegro, what’s happening in realms of, you know, in terms of the team and funding, et cetera? So, we’re a series A company. We’re about 30 people. We’re an open-source company. So, most of our platform is completely open. And so, we’re actually undertaking what Andreessen Horowitz calls a B2B growth sales strategy. So, we’re pushing on getting a lot of companies to adopt our solution, knowing that they’re going to upsell into -- at some point to some enterprise solution. And so, that’s going well. I can’t release numbers, but we’re going really, really fast. That’s wonderful. Okay. Nir, I have you for just a few more minutes. - Sure. - But I'd love to -- And I'd love to pick your brain. What are you most passionate about in the realm of the AI space? And if you think five years down the line, realistically, what are the things that you are most excited about that I will get to experience in my 20s now? [laughs] What I’m most passionate about is what got me here in the first place. I mean, this is -- So, I spent about a decade at Google. And after you are at Google and you're doing a lot of things that really impact huge swaths of humanity, really, it’s -- you really learn about -- you want to innovate, and you want to do something that’s impactful. And that’s really -- that’s been the driving force for me across my whole career ―how to actually innovate and push the envelope or be part of something that pushes it to the next stage, and really be able to have a large impact. I think that AI, obviously, is meant to have a large -- a huge impact on humanity in so many aspects. And so, for us, it’s really about making that happen. I think that there’s a really big disparity between where the media is today and what’s actually happening. Most of the companies are struggling with this. And so, to me, if you’re asking, realistically, what we’re going to see in the next several years is we’re going to see a lot of the -- the things that you’re already seeing out of Google, et cetera, becomes standard, everyday things where it’s normal for you to do that, right? It’s normal for you to talk to a bot, right? That’s completely animated. It’s normal for companies to be able to automatically figure out who are the best customers and where they need to target it, right? It’s very easy to be able to understand what you’re seeing in video, et cetera, right? I had recently talked with a product manager at Waymo. And one of the very interesting things that she mentioned was the media and a lot of companies were very quick to make these crazy assumptions that, yeah, by the year 2020, we’re going to have vehicles on the road. But then, people -- because people though that the problem was a little bit, I think, easier than what it is. And all of a sudden, they got to 95% mark. And then, they realized that that last sliver, which is critical when you’re talking about lives, that’s going to take a little bit longer. So, I agree. And I definitely look forward to seeing more things progress. I’m very excited about my own studies with AI and getting a deeper understanding myself to be able to harness these qualities as well. We’re almost out of time, but I have to ask you my favorite question. I would love to know three words that you would best describe yourself. Very curious for that now. Yeah. So, you warned me about this, - Yeah. - right before but I didn't have time to think about it But let me tell you about the -- So, let me give you a different answer, slightly different -- When I look at the leaders and managers that I aspire to be like, right? I saw people who are pushing the envelope, who are able to take bold decisions. I saw people who deeply care about the success -- their success within the context of the organization, not a me-first. And also, deeply care about who -- their team and the people that work for them, and their success, again, within that context. And then, at the end of the day, having -- doing everything with integrity. And so, when you ask me, this is what I aspire to be. I love it. I love it. I think it's just -- And I’m sure it’s such a -- both fascinating, difficult, and fun journey at the same time to now lead a company that’s growing quickly, and you have to now really formulate your own leadership style, and what does it mean to be a leader in that aspect. I recall you were captain in the IDF as well, which I’m sure has a... a lot of connections to some of the things that you’re experiencing now. But it sounds wonderful, Nir. Best of luck with Allegro. Thank you for the inspiration over these last 20 minutes, and I look forward to keeping in touch. Thank you so much, Michael. It’s been a pleasure. And obviously, all the success to you. And maybe, you can come work for us or use our tools. - Done. Bye-bye. [laughter] All right. Take care, Nir. - Take care, Michael. - Bye-bye. Bye-bye.